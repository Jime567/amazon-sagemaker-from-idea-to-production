{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0551f521-eaea-4e5c-a9a9-60a93aaa018e",
   "metadata": {},
   "source": [
    "#Â Step 6: Add data monitoring\n",
    "After executing six previous notebooks, you have a production-ready solution with automated model building and model deployment CI/CD pipelines.\n",
    "This notebook adds continuous monitoring of the data quality in real-time. [Amazon SageMaker model monitor](https://aws.amazon.com/sagemaker/model-monitor/) enables you to set up an automated alert triggering system when there are deviations in the data and model quality, such as data drift and anomalies.\n",
    "\n",
    "\n",
    "\n",
    "![](img/six-steps-6.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "a2681315-b19c-4e97-a49e-21f04efb6bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker \n",
    "import json\n",
    "from sagemaker.model_monitor import DataCaptureConfig\n",
    "from sagemaker.predictor import Predictor\n",
    "import time\n",
    "from time import gmtime, strftime\n",
    "import uuid\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sagemaker.model_monitor import DefaultModelMonitor\n",
    "from sagemaker.model_monitor.dataset_format import DatasetFormat\n",
    "from sagemaker.model_monitor import CronExpressionGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8b8d993-1c33-40ad-96ee-7340edadcc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = boto3.client(\"sagemaker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9d2fb029-39b2-48ee-a3d6-38f1a42f25ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored variables and their in-db values:\n",
      "abalone_dataset_file_name                -> 'abalone.csv'\n",
      "abalone_dataset_local_url                -> '../dataset/abalone.csv'\n",
      "auto_ml_job_name                         -> 'automl-asinproc-24-14-33-56'\n",
      "baseline_s3_url                          -> 's3://sagemaker-us-east-1-906545278380/from-idea-t\n",
      "bucket_name                              -> 'sagemaker-us-east-1-906545278380'\n",
      "bucket_prefix                            -> 'from-idea-to-prod/xgboost'\n",
      "customers_count                          -> 10000\n",
      "customers_feature_group_name             -> 'fscw-customers-07-20-17-46'\n",
      "data_bucket                              -> 'sagemaker-us-east-1-906545278380'\n",
      "data_capture_prefix                      -> 'from-idea-to-prod/datacapture'\n",
      "data_uploaded                            -> True\n",
      "domain_id                                -> 'd-r8pbvl3oamh6'\n",
      "dw_flow_file_url                         -> 's3://sagemaker-us-east-1-906545278380/feature-sto\n",
      "dw_output_name                           -> '928854ec-259e-4130-8e0f-b65221b27d6e.default'\n",
      "endpoint_name                            -> 'reorder-classifier-2022-07-20-19-45-09-338'\n",
      "execution_role                           -> 'arn:aws:iam::906545278380:role/service-role/Amazo\n",
      "feature_group_name                       -> 'FG-abalone-06-19-27-51-42ea2f48'\n",
      "freq                                     -> '2H'\n",
      "initialized                              -> True\n",
      "input_s3_url                             -> 's3://sagemaker-us-east-1-906545278380/from-idea-t\n",
      "model_package_group_name                 -> 'from-idea-to-prod-model-group'\n",
      "orders_count                             -> 100000\n",
      "orders_feature_group_name                -> 'fscw-orders-07-20-17-46'\n",
      "output_s3_url                            -> 's3://sagemaker-us-east-1-906545278380/from-idea-t\n",
      "products_count                           -> 17001\n",
      "products_feature_group_name              -> 'fscw-products-07-20-17-46'\n",
      "project_prefix                           -> 'loan-defaults'\n",
      "query_string                             -> 'SELECT * FROM \"fscw-customers-07-20-17-46-1658339\n",
      "region                                   -> 'us-east-1'\n",
      "reports_prefix                           -> 'from-idea-to-prod/reports'\n",
      "s3_data_output_prefix                    -> 's3://sagemaker-us-east-1-906545278380/loan-defaul\n",
      "s3_data_prefix                           -> 's3://sagemaker-us-east-1-906545278380/loan-defaul\n",
      "s3_flow_prefix                           -> 's3://sagemaker-us-east-1-906545278380/loan-defaul\n",
      "s3_fs_query_output_prefix                -> 'sagemaker-us-east-1-906545278380/feature-store-in\n",
      "s3_input_data_prefix                     -> 'sagemaker-us-east-1-906545278380/feature-store-in\n",
      "s3_path                                  -> 's3://sagemaker-us-east-1-906545278380/loan-defaul\n",
      "s3_path_data                             -> 's3://sagemaker-us-east-1-906545278380/loan-defaul\n",
      "s3_test                                  -> 's3://sagemaker-us-east-1-906545278380/loan-defaul\n",
      "s3_to_fs_pipeline_name                   -> 's3-fs-ingest-pipeline-p-iwfgodxukuoo'\n",
      "sm_role                                  -> 'arn:aws:iam::906545278380:role/service-role/Amazo\n",
      "target_col                               -> 'y'\n",
      "test_data_s3_path                        -> 's3://sagemaker-us-east-1-906545278380/asin/test/t\n",
      "train_s3_url                             -> 's3://sagemaker-us-east-1-906545278380/from-idea-t\n",
      "training_jobName                         -> 'reorder-classifier-2022-07-20-19-38-33-550'\n",
      "tuning_job_name                          -> 'mlu-dl1-xgb-tuning-220125-1108'\n",
      "xgb_train_job_name                       -> 'loan-defaults-2022-04-28-11-22-01-124'\n"
     ]
    }
   ],
   "source": [
    "%store -r \n",
    "\n",
    "%store\n",
    "\n",
    "try:\n",
    "    initialized\n",
    "except NameError:\n",
    "    print(\"+++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    print(\"[ERROR] YOU HAVE TO RUN 00-start-here notebook   \")\n",
    "    print(\"+++++++++++++++++++++++++++++++++++++++++++++++++\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ae4a24-1294-4bda-8f68-4e811025932d",
   "metadata": {},
   "source": [
    "## How model monitor works\n",
    "Amazon SageMaker Model Monitor automatically monitors ML models in production and notifies you when quality issues arise. Model Monitor uses rules to detect drift in your models and data and alerts you when it happens. The following figure shows how this process works.\n",
    "\n",
    "![](img/model-monitor.png)\n",
    "\n",
    "The process for setting up the data monitoring:\n",
    "1. Enable the endpoint to capture data from incoming requests to a trained ML model and the resulting model predictions\n",
    "2. Create a baseline from the dataset that was used to train the model. The baseline computes metrics and suggests constraints for the metrics. Real-time predictions from your model are compared to the constraints, and are reported as violations if they are outside the constrained values\n",
    "3. Create a monitoring schedule specifying what data to collect, how often to collect it, how to analyze it, and which reports to produce\n",
    "4. Inspect the reports, which compare the latest data with the baseline, and watch for any violations reported and for metrics and notifications from Amazon CloudWatch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f977d10-057f-4d9f-85ba-17b5dd7ebff6",
   "metadata": {},
   "source": [
    "## Real-time inference data capture from a SageMaker endpoint\n",
    "To demonstrate the usage of model monitor we use the existing endpoints deployed by the deployment pipeline in the step 5 notebook.\n",
    "\n",
    "The model deployment MLOps project implemented in the step 5 notebook contains a data capture configuration for the deployed endpoints. If you clone the project's code repository to the Studio file system, you can see the project files.\n",
    "\n",
    "The CloudFormation deployment template `endpoint-config-template.yml` enables data capture for the endpoint configuration:\n",
    "```yaml\n",
    "EndpointConfig:\n",
    "    Type: AWS::SageMaker::EndpointConfig\n",
    "    Properties:\n",
    "      ProductionVariants:\n",
    "        - InitialInstanceCount: !Ref EndpointInstanceCount\n",
    "          InitialVariantWeight: 1.0\n",
    "          InstanceType: !Ref EndpointInstanceType\n",
    "          ModelName: !GetAtt Model.ModelName\n",
    "          VariantName: AllTraffic\n",
    "      DataCaptureConfig:\n",
    "          EnableCapture: !Ref EnableDataCapture \n",
    "          InitialSamplingPercentage: !Ref SamplingPercentage\n",
    "          DestinationS3Uri: !Ref DataCaptureUploadPath\n",
    "          CaptureOptions:\n",
    "            - CaptureMode: Input\n",
    "            - CaptureMode: Output\n",
    "          CaptureContentTypeHeader:\n",
    "            CsvContentTypes:\n",
    "              - \"text/csv\"\n",
    "```\n",
    "\n",
    "The configuration files `prod-config.json` and `staging-config.json` provide the actual values for `EnableCapture`, `InitialSamplingPercentage`, and `DestinationS3Uri`:\n",
    "```json\n",
    "{\n",
    "  \"Parameters\": {\n",
    "    \"StageName\": \"prod\",\n",
    "    \"EndpointInstanceCount\": \"1\",\n",
    "    \"EndpointInstanceType\": \"ml.m5.large\",\n",
    "    \"SamplingPercentage\": \"80\",\n",
    "    \"EnableDataCapture\": \"true\"\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "Let's check the endpoint configuration and see how data capture is confgured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c70bcd2e-95f9-4dfd-9830-a48b579c7c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data capture configuration for step5-deploy-model-prod:\n",
      "{\n",
      "  \"EnableCapture\": true,\n",
      "  \"CaptureStatus\": \"Started\",\n",
      "  \"CurrentSamplingPercentage\": 80,\n",
      "  \"DestinationS3Uri\": \"s3://sagemaker-project-p-yh0gano2qax2/datacapture-prod\"\n",
      "}\n",
      "Data capture configuration for step5-deploy-model-staging:\n",
      "{\n",
      "  \"EnableCapture\": true,\n",
      "  \"CaptureStatus\": \"Started\",\n",
      "  \"CurrentSamplingPercentage\": 100,\n",
      "  \"DestinationS3Uri\": \"s3://sagemaker-project-p-yh0gano2qax2/datacapture-staging\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "for ep in sm.list_endpoints(StatusEquals=\"InService\")[\"Endpoints\"]:\n",
    "    print(f\"Data capture configuration for {ep['EndpointName']}:\")\n",
    "    print(f\"{json.dumps(sm.describe_endpoint(EndpointName=ep['EndpointName'])['DataCaptureConfig'], indent=2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a891b9fe-37a3-44fa-a1d6-2fe94262410c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the configuration for a specific endpoint name\n",
    "endpoint_name = \"step5-deploy-model-prod\"\n",
    "data_capture_uri = sm.describe_endpoint(EndpointName=endpoint_name)['DataCaptureConfig']['DestinationS3Uri']\n",
    "data_capture_bucket = data_capture_uri.split('/')[2]\n",
    "data_capture_prefix = '/'.join(data_capture_uri.split('/')[3:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190e011d-ba01-43c8-8af9-959bb7835574",
   "metadata": {},
   "source": [
    "### Generate captured data\n",
    "You must send some data to an endpoint for inference to generate data capture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b1d0fd2a-65e6-48d2-ab50-2e6cf8597f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-27 10:58:57    5846610 datacapture-prod/step5-deploy-model-prod/AllTraffic/2022/09/27/10/57-23-493-215917dc-5813-474e-a145-2f21e7eaa2a3.jsonl\n",
      "2022-09-27 11:00:36    4677288 datacapture-prod/step5-deploy-model-prod/AllTraffic/2022/09/27/10/58-58-063-04b60d38-d87f-4add-9707-82a8a3c30103.jsonl\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls s3://sagemaker-project-p-yh0gano2qax2/datacapture-prod/ --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "58229914-7fa6-4d5c-841b-2bbc32c6add5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = Predictor(\n",
    "    endpoint_name=endpoint_name, \n",
    "    serializer=sagemaker.serializers.CSVSerializer(),\n",
    "    deserializer=sagemaker.deserializers.CSVDeserializer()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "652224c3-4121-41c1-9494-f4d8a287f2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = pd.read_csv(\"tmp/test_x.csv\", names=[f'{i}' for i in range(59)])\n",
    "test_y = pd.read_csv(\"tmp/test_y.csv\", names=['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "8f7da46e-d957-4351-a804-2724cd0c3869",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_endpoint_traffic(predictor, repeats=10):\n",
    "    for _ in range(0,repeats):\n",
    "        print(\"sending inference data to the endpoint\")\n",
    "        predictions = np.array(predictor.predict(test_x.values), dtype=float).squeeze()\n",
    "        print(predictions)\n",
    "        time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "150cdd96-de42-4b63-9925-415097ecc680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sending inference data to the endpoint\n",
      "[0.05137555 0.09782112 0.22581661 ... 0.04346842 0.04000453 0.03656681]\n",
      "sending inference data to the endpoint\n",
      "[0.05137555 0.09782112 0.22581661 ... 0.04346842 0.04000453 0.03656681]\n",
      "sending inference data to the endpoint\n",
      "[0.05137555 0.09782112 0.22581661 ... 0.04346842 0.04000453 0.03656681]\n",
      "sending inference data to the endpoint\n",
      "[0.05137555 0.09782112 0.22581661 ... 0.04346842 0.04000453 0.03656681]\n",
      "sending inference data to the endpoint\n",
      "[0.05137555 0.09782112 0.22581661 ... 0.04346842 0.04000453 0.03656681]\n",
      "sending inference data to the endpoint\n",
      "[0.05137555 0.09782112 0.22581661 ... 0.04346842 0.04000453 0.03656681]\n",
      "sending inference data to the endpoint\n",
      "[0.05137555 0.09782112 0.22581661 ... 0.04346842 0.04000453 0.03656681]\n",
      "sending inference data to the endpoint\n",
      "[0.05137555 0.09782112 0.22581661 ... 0.04346842 0.04000453 0.03656681]\n",
      "sending inference data to the endpoint\n",
      "[0.05137555 0.09782112 0.22581661 ... 0.04346842 0.04000453 0.03656681]\n",
      "sending inference data to the endpoint\n",
      "[0.05137555 0.09782112 0.22581661 ... 0.04346842 0.04000453 0.03656681]\n"
     ]
    }
   ],
   "source": [
    "generate_endpoint_traffic(predictor, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1ca97e-2129-4371-9695-c08d3e46f11b",
   "metadata": {},
   "source": [
    "### View captured data\n",
    "Now list the data capture files stored in Amazon S3. The data is stored as `jsonl` an Amazon S3 path format is `s3://{destination-bucket-prefix}/{endpoint-name}/{variant-name}/yyyy/mm/dd/hh/filename.jsonl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "88b6a4c5-09ae-464e-a24a-9c474e6ae10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found data capture files:\n",
      "datacapture-prod/step5-deploy-model-prod/AllTraffic/2022/09/27/10/57-23-493-215917dc-5813-474e-a145-2f21e7eaa2a3.jsonl\n",
      " datacapture-prod/step5-deploy-model-prod/AllTraffic/2022/09/27/10/58-58-063-04b60d38-d87f-4add-9707-82a8a3c30103.jsonl\n"
     ]
    }
   ],
   "source": [
    "s3_client = boto3.Session().client(\"s3\")\n",
    "\n",
    "capture_files = [\n",
    "    capture_file.get(\"Key\") \n",
    "    for capture_file in s3_client.list_objects(Bucket=data_capture_bucket, Prefix=data_capture_prefix).get(\"Contents\")\n",
    "]\n",
    "print(\"Found data capture files:\")\n",
    "print(\"\\n \".join(capture_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60ba1b4-8e39-4b1b-8f17-3253e6cb0a9b",
   "metadata": {},
   "source": [
    "Each inference request is captured in one line in the `jsonl` file. The line contains both the input and output merged together. In the example, you provided the ContentType as `text/csv` which is reflected in the `observedContentType` value. Also, you expose the encoding that you used to encode the input and output payloads in the capture format with the encoding value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "71d889d7-f212-4414-9c08-b15d14754048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"captureData\":{\"endpointInput\":{\"observedContentType\":\"text/csv\",\"mode\":\"INPUT\",\"data\":\"25,1,999,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0,0,0,0,1,0,0,0,0,1,0,0,0,0,1,1,0,0,0,1,0,0,0,0,1,0,0,0,0,0,0,1,0,0,0,0,1,0\\n28,3,999,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,1,0,0,0,0,0,1,0,0,1,0,0,1,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0,0,1,0\\n38,1,999,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0,1,0,0,1,0,0,1,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,0\\n32,1,999,1,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,1,1,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,1,0,0,0,1,0,0\\n40,1,999,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0,0,0,0,1,0,0,0,0,1,0,0,0,0,1,0,0,1,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0,0,1,0\\n55,3,999,0,1,1,0,0,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,1,0,0,0,1,1,0,0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,1,0\\n31,3,999,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,1,0,0,0,0,1,0,0,1,0,0,1,0,0,1,0,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,1,0\\n30,2,999,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,\n"
     ]
    }
   ],
   "source": [
    "def get_obj_body(obj_key):\n",
    "    return s3_client.get_object(Bucket=data_capture_bucket, Key=obj_key).get(\"Body\").read().decode(\"utf-8\")\n",
    "\n",
    "capture_file = get_obj_body(capture_files[-1])\n",
    "print(capture_file[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ada3476-3067-47e8-bcc1-f515972048c2",
   "metadata": {},
   "source": [
    "## Model monitor - monitor data quality\n",
    "In this example you learn how to setup data quality monitoring.\n",
    "\n",
    "To enable inference data quality monitoring and evaluation you must:\n",
    "1. Enable [data capture](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-data-capture.html)\n",
    "1. [Create a baseline](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-create-baseline.html) with which you compare the realtime traffic\n",
    "1. Once a baseline is ready, [schedule monitoring jobs](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-scheduling.html) to continously evaluate and compare against the baseline\n",
    "1. [Interpret the results](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-interpreting-results.html) of monitoring jobs\n",
    "1. [Integrate data quality monitoring](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-interpreting-cloudwatch.html) with Amazon CloudWatch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84268bba-f44e-4cb4-a53f-67251253c1a4",
   "metadata": {},
   "source": [
    "### Create a baselineing job with training dataset\n",
    "The training dataset with which you trained the model is usually a good baseline dataset. Note that the training dataset data schema and the inference dataset schema should exactly match (i.e. the number and order of the features).\n",
    "\n",
    "From the training dataset you can ask Amazon SageMaker to suggest a set of baseline _constraints_ and generate descriptive _statistics_ to explore the data. Model Monitor provides a [built-in container](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-pre-built-container.html) that provides the ability to suggest the constraints automatically for CSV and flat JSON input. This `sagemaker-model-monitor-analyzer` container also provides you with a range of model monitoring capabilities, including constraint validation against a baseline, and emitting Amazon CloudWatch metrics. This container is based on Spark and is built with [Deequ](https://github.com/awslabs/deequ). All column names in your baseline dataset must be compliant with Spark. For column names, use only lowercase characters, and _ as the only special character.\n",
    "\n",
    "We use the training dataset you created in the step 2 notebook data processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "fbaac6de-b3a9-4f4d-b6e2-2f2a66b86a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-28 07:07:51    3544984 train.csv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls {train_s3_url}/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "632362d5-c4e0-4bf5-bca4-b4da6ad34377",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_results_s3_url = f\"{baseline_s3_url}/results\"\n",
    "reports_s3_url = f\"{baseline_s3_url}/reports\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "774449c4-e71a-4206-9d03-09821f6e1f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_dataset_uri = f\"{train_s3_url}/train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "7b765256-592c-4b4e-bc7e-f7176aede653",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_job_name = f\"from-idea-to-prod-processing-baselining-{strftime('%d-%H-%M-%S', gmtime())}-{str(uuid.uuid4())[:8]}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d49b158-9859-4053-8ec9-8f99577ed07e",
   "metadata": {},
   "source": [
    "Start a SageMaker projcessing job on the baseline data to profile data and suggest constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "5443d53d-00e9-4320-9c72-1751fe796778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  from-idea-to-prod-processing-baselining-28-08-25-51-a13f8446\n",
      "Inputs:  [{'InputName': 'baseline_dataset_input', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-906545278380/from-idea-to-prod/xgboost/train/train.csv', 'LocalPath': '/opt/ml/processing/input/baseline_dataset_input', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'monitoring_output', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-906545278380/from-idea-to-prod/xgboost/baseline/results', 'LocalPath': '/opt/ml/processing/output', 'S3UploadMode': 'EndOfJob'}}]\n",
      "......................................................................!"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sagemaker.processing.ProcessingJob at 0x7f798832f0d0>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_monitor = DefaultModelMonitor(\n",
    "    role=sm_role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    volume_size_in_gb=20,\n",
    "    max_runtime_in_seconds=3600,\n",
    ")\n",
    "\n",
    "data_monitor.suggest_baseline(\n",
    "    baseline_dataset=baseline_dataset_uri,\n",
    "    dataset_format=DatasetFormat.csv(header=False),\n",
    "    output_s3_uri=baseline_results_s3_url,\n",
    "    wait=True,\n",
    "    logs=False,\n",
    "    job_name=baseline_job_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29e9063-5fb6-4bda-86c1-d33b2b0ca10b",
   "metadata": {},
   "source": [
    "### See the generated statistics and constraints\n",
    "The baselining jobs saves the baseline statistics to the `statistics.json` file and the suggested baseline constraints to the `constraints.json` file in the location you specify with `output_s3_uri`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "ff77ab21-f595-417e-a880-a3cb73be87c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-28 08:31:50       9423 constraints.json\n",
      "2022-09-28 08:31:50    1558448 statistics.json\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls {baseline_results_s3_url}/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "dc1f849c-8ca0-4c7f-a3a4-eac7b7553b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: pandas.io.json.json_normalize is deprecated, use pandas.json_normalize instead\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>inferred_type</th>\n",
       "      <th>numerical_statistics.common.num_present</th>\n",
       "      <th>numerical_statistics.common.num_missing</th>\n",
       "      <th>numerical_statistics.mean</th>\n",
       "      <th>numerical_statistics.sum</th>\n",
       "      <th>numerical_statistics.std_dev</th>\n",
       "      <th>numerical_statistics.min</th>\n",
       "      <th>numerical_statistics.max</th>\n",
       "      <th>numerical_statistics.distribution.kll.buckets</th>\n",
       "      <th>numerical_statistics.distribution.kll.sketch.parameters.c</th>\n",
       "      <th>numerical_statistics.distribution.kll.sketch.parameters.k</th>\n",
       "      <th>numerical_statistics.distribution.kll.sketch.data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>_c0</td>\n",
       "      <td>Integral</td>\n",
       "      <td>28831</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111651</td>\n",
       "      <td>3219.0</td>\n",
       "      <td>0.314936</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>_c1</td>\n",
       "      <td>Integral</td>\n",
       "      <td>28831</td>\n",
       "      <td>0</td>\n",
       "      <td>40.007943</td>\n",
       "      <td>1153469.0</td>\n",
       "      <td>10.390958</td>\n",
       "      <td>17.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>[{'lower_bound': 17.0, 'upper_bound': 25.1, 'c...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[44.0, 29.0, 30.0, 37.0, 37.0, 44.0, 54.0, 36...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>_c2</td>\n",
       "      <td>Integral</td>\n",
       "      <td>28831</td>\n",
       "      <td>0</td>\n",
       "      <td>2.573376</td>\n",
       "      <td>74193.0</td>\n",
       "      <td>2.803649</td>\n",
       "      <td>1.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>[{'lower_bound': 1.0, 'upper_bound': 6.5, 'cou...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[8.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 5.0, 2.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_c3</td>\n",
       "      <td>Integral</td>\n",
       "      <td>28831</td>\n",
       "      <td>0</td>\n",
       "      <td>961.082307</td>\n",
       "      <td>27708964.0</td>\n",
       "      <td>190.294629</td>\n",
       "      <td>0.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 99.9, 'co...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[999.0, 4.0, 999.0, 999.0, 999.0, 999.0, 999....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>_c4</td>\n",
       "      <td>Integral</td>\n",
       "      <td>28831</td>\n",
       "      <td>0</td>\n",
       "      <td>0.176407</td>\n",
       "      <td>5086.0</td>\n",
       "      <td>0.506651</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 0.7, 'cou...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>_c5</td>\n",
       "      <td>Integral</td>\n",
       "      <td>28831</td>\n",
       "      <td>0</td>\n",
       "      <td>0.961812</td>\n",
       "      <td>27730.0</td>\n",
       "      <td>0.191650</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>_c6</td>\n",
       "      <td>Integral</td>\n",
       "      <td>28831</td>\n",
       "      <td>0</td>\n",
       "      <td>0.086851</td>\n",
       "      <td>2504.0</td>\n",
       "      <td>0.281617</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>_c7</td>\n",
       "      <td>Integral</td>\n",
       "      <td>28831</td>\n",
       "      <td>0</td>\n",
       "      <td>0.251916</td>\n",
       "      <td>7263.0</td>\n",
       "      <td>0.434113</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>_c8</td>\n",
       "      <td>Integral</td>\n",
       "      <td>28831</td>\n",
       "      <td>0</td>\n",
       "      <td>0.223787</td>\n",
       "      <td>6452.0</td>\n",
       "      <td>0.416781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>_c9</td>\n",
       "      <td>Integral</td>\n",
       "      <td>28831</td>\n",
       "      <td>0</td>\n",
       "      <td>0.035899</td>\n",
       "      <td>1035.0</td>\n",
       "      <td>0.186038</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>_c10</td>\n",
       "      <td>Integral</td>\n",
       "      <td>28831</td>\n",
       "      <td>0</td>\n",
       "      <td>0.025424</td>\n",
       "      <td>733.0</td>\n",
       "      <td>0.157409</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>_c11</td>\n",
       "      <td>Integral</td>\n",
       "      <td>28831</td>\n",
       "      <td>0</td>\n",
       "      <td>0.071277</td>\n",
       "      <td>2055.0</td>\n",
       "      <td>0.257288</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>_c12</td>\n",
       "      <td>Integral</td>\n",
       "      <td>28831</td>\n",
       "      <td>0</td>\n",
       "      <td>0.040651</td>\n",
       "      <td>1172.0</td>\n",
       "      <td>0.197480</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>_c13</td>\n",
       "      <td>Integral</td>\n",
       "      <td>28831</td>\n",
       "      <td>0</td>\n",
       "      <td>0.033957</td>\n",
       "      <td>979.0</td>\n",
       "      <td>0.181117</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>_c14</td>\n",
       "      <td>Integral</td>\n",
       "      <td>28831</td>\n",
       "      <td>0</td>\n",
       "      <td>0.096944</td>\n",
       "      <td>2795.0</td>\n",
       "      <td>0.295882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>_c15</td>\n",
       "      <td>Integral</td>\n",
       "      <td>28831</td>\n",
       "      <td>0</td>\n",
       "      <td>0.020880</td>\n",
       "      <td>602.0</td>\n",
       "      <td>0.142984</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>_c16</td>\n",
       "      <td>Integral</td>\n",
       "      <td>28831</td>\n",
       "      <td>0</td>\n",
       "      <td>0.165412</td>\n",
       "      <td>4769.0</td>\n",
       "      <td>0.371552</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>_c17</td>\n",
       "      <td>Integral</td>\n",
       "      <td>28831</td>\n",
       "      <td>0</td>\n",
       "      <td>0.025320</td>\n",
       "      <td>730.0</td>\n",
       "      <td>0.157095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>_c18</td>\n",
       "      <td>Integral</td>\n",
       "      <td>28831</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008532</td>\n",
       "      <td>246.0</td>\n",
       "      <td>0.091977</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>_c19</td>\n",
       "      <td>Integral</td>\n",
       "      <td>28831</td>\n",
       "      <td>0</td>\n",
       "      <td>0.112448</td>\n",
       "      <td>3242.0</td>\n",
       "      <td>0.315917</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name inferred_type  numerical_statistics.common.num_present  \\\n",
       "0    _c0      Integral                                    28831   \n",
       "1    _c1      Integral                                    28831   \n",
       "2    _c2      Integral                                    28831   \n",
       "3    _c3      Integral                                    28831   \n",
       "4    _c4      Integral                                    28831   \n",
       "5    _c5      Integral                                    28831   \n",
       "6    _c6      Integral                                    28831   \n",
       "7    _c7      Integral                                    28831   \n",
       "8    _c8      Integral                                    28831   \n",
       "9    _c9      Integral                                    28831   \n",
       "10  _c10      Integral                                    28831   \n",
       "11  _c11      Integral                                    28831   \n",
       "12  _c12      Integral                                    28831   \n",
       "13  _c13      Integral                                    28831   \n",
       "14  _c14      Integral                                    28831   \n",
       "15  _c15      Integral                                    28831   \n",
       "16  _c16      Integral                                    28831   \n",
       "17  _c17      Integral                                    28831   \n",
       "18  _c18      Integral                                    28831   \n",
       "19  _c19      Integral                                    28831   \n",
       "\n",
       "    numerical_statistics.common.num_missing  numerical_statistics.mean  \\\n",
       "0                                         0                   0.111651   \n",
       "1                                         0                  40.007943   \n",
       "2                                         0                   2.573376   \n",
       "3                                         0                 961.082307   \n",
       "4                                         0                   0.176407   \n",
       "5                                         0                   0.961812   \n",
       "6                                         0                   0.086851   \n",
       "7                                         0                   0.251916   \n",
       "8                                         0                   0.223787   \n",
       "9                                         0                   0.035899   \n",
       "10                                        0                   0.025424   \n",
       "11                                        0                   0.071277   \n",
       "12                                        0                   0.040651   \n",
       "13                                        0                   0.033957   \n",
       "14                                        0                   0.096944   \n",
       "15                                        0                   0.020880   \n",
       "16                                        0                   0.165412   \n",
       "17                                        0                   0.025320   \n",
       "18                                        0                   0.008532   \n",
       "19                                        0                   0.112448   \n",
       "\n",
       "    numerical_statistics.sum  numerical_statistics.std_dev  \\\n",
       "0                     3219.0                      0.314936   \n",
       "1                  1153469.0                     10.390958   \n",
       "2                    74193.0                      2.803649   \n",
       "3                 27708964.0                    190.294629   \n",
       "4                     5086.0                      0.506651   \n",
       "5                    27730.0                      0.191650   \n",
       "6                     2504.0                      0.281617   \n",
       "7                     7263.0                      0.434113   \n",
       "8                     6452.0                      0.416781   \n",
       "9                     1035.0                      0.186038   \n",
       "10                     733.0                      0.157409   \n",
       "11                    2055.0                      0.257288   \n",
       "12                    1172.0                      0.197480   \n",
       "13                     979.0                      0.181117   \n",
       "14                    2795.0                      0.295882   \n",
       "15                     602.0                      0.142984   \n",
       "16                    4769.0                      0.371552   \n",
       "17                     730.0                      0.157095   \n",
       "18                     246.0                      0.091977   \n",
       "19                    3242.0                      0.315917   \n",
       "\n",
       "    numerical_statistics.min  numerical_statistics.max  \\\n",
       "0                        0.0                       1.0   \n",
       "1                       17.0                      98.0   \n",
       "2                        1.0                      56.0   \n",
       "3                        0.0                     999.0   \n",
       "4                        0.0                       7.0   \n",
       "5                        0.0                       1.0   \n",
       "6                        0.0                       1.0   \n",
       "7                        0.0                       1.0   \n",
       "8                        0.0                       1.0   \n",
       "9                        0.0                       1.0   \n",
       "10                       0.0                       1.0   \n",
       "11                       0.0                       1.0   \n",
       "12                       0.0                       1.0   \n",
       "13                       0.0                       1.0   \n",
       "14                       0.0                       1.0   \n",
       "15                       0.0                       1.0   \n",
       "16                       0.0                       1.0   \n",
       "17                       0.0                       1.0   \n",
       "18                       0.0                       1.0   \n",
       "19                       0.0                       1.0   \n",
       "\n",
       "        numerical_statistics.distribution.kll.buckets  \\\n",
       "0   [{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...   \n",
       "1   [{'lower_bound': 17.0, 'upper_bound': 25.1, 'c...   \n",
       "2   [{'lower_bound': 1.0, 'upper_bound': 6.5, 'cou...   \n",
       "3   [{'lower_bound': 0.0, 'upper_bound': 99.9, 'co...   \n",
       "4   [{'lower_bound': 0.0, 'upper_bound': 0.7, 'cou...   \n",
       "5   [{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...   \n",
       "6   [{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...   \n",
       "7   [{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...   \n",
       "8   [{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...   \n",
       "9   [{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...   \n",
       "10  [{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...   \n",
       "11  [{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...   \n",
       "12  [{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...   \n",
       "13  [{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...   \n",
       "14  [{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...   \n",
       "15  [{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...   \n",
       "16  [{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...   \n",
       "17  [{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...   \n",
       "18  [{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...   \n",
       "19  [{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...   \n",
       "\n",
       "    numerical_statistics.distribution.kll.sketch.parameters.c  \\\n",
       "0                                                0.64           \n",
       "1                                                0.64           \n",
       "2                                                0.64           \n",
       "3                                                0.64           \n",
       "4                                                0.64           \n",
       "5                                                0.64           \n",
       "6                                                0.64           \n",
       "7                                                0.64           \n",
       "8                                                0.64           \n",
       "9                                                0.64           \n",
       "10                                               0.64           \n",
       "11                                               0.64           \n",
       "12                                               0.64           \n",
       "13                                               0.64           \n",
       "14                                               0.64           \n",
       "15                                               0.64           \n",
       "16                                               0.64           \n",
       "17                                               0.64           \n",
       "18                                               0.64           \n",
       "19                                               0.64           \n",
       "\n",
       "    numerical_statistics.distribution.kll.sketch.parameters.k  \\\n",
       "0                                              2048.0           \n",
       "1                                              2048.0           \n",
       "2                                              2048.0           \n",
       "3                                              2048.0           \n",
       "4                                              2048.0           \n",
       "5                                              2048.0           \n",
       "6                                              2048.0           \n",
       "7                                              2048.0           \n",
       "8                                              2048.0           \n",
       "9                                              2048.0           \n",
       "10                                             2048.0           \n",
       "11                                             2048.0           \n",
       "12                                             2048.0           \n",
       "13                                             2048.0           \n",
       "14                                             2048.0           \n",
       "15                                             2048.0           \n",
       "16                                             2048.0           \n",
       "17                                             2048.0           \n",
       "18                                             2048.0           \n",
       "19                                             2048.0           \n",
       "\n",
       "    numerical_statistics.distribution.kll.sketch.data  \n",
       "0   [[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "1   [[44.0, 29.0, 30.0, 37.0, 37.0, 44.0, 54.0, 36...  \n",
       "2   [[8.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 5.0, 2.0,...  \n",
       "3   [[999.0, 4.0, 999.0, 999.0, 999.0, 999.0, 999....  \n",
       "4   [[1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "5   [[1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...  \n",
       "6   [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "7   [[1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0,...  \n",
       "8   [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0,...  \n",
       "9   [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "10  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "11  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "12  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "13  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "14  [[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0,...  \n",
       "15  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "16  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "17  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "18  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "19  [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_job = data_monitor.latest_baselining_job\n",
    "schema_df = pd.io.json.json_normalize(baseline_job.baseline_statistics().body_dict[\"features\"])\n",
    "schema_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "2fdb5f66-da5c-477f-b66a-3997713404bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: pandas.io.json.json_normalize is deprecated, use pandas.json_normalize instead\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>inferred_type</th>\n",
       "      <th>completeness</th>\n",
       "      <th>num_constraints.is_non_negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>_c0</td>\n",
       "      <td>Integral</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>_c1</td>\n",
       "      <td>Integral</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>_c2</td>\n",
       "      <td>Integral</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_c3</td>\n",
       "      <td>Integral</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>_c4</td>\n",
       "      <td>Integral</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>_c5</td>\n",
       "      <td>Integral</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>_c6</td>\n",
       "      <td>Integral</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>_c7</td>\n",
       "      <td>Integral</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>_c8</td>\n",
       "      <td>Integral</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>_c9</td>\n",
       "      <td>Integral</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  name inferred_type  completeness  num_constraints.is_non_negative\n",
       "0  _c0      Integral           1.0                             True\n",
       "1  _c1      Integral           1.0                             True\n",
       "2  _c2      Integral           1.0                             True\n",
       "3  _c3      Integral           1.0                             True\n",
       "4  _c4      Integral           1.0                             True\n",
       "5  _c5      Integral           1.0                             True\n",
       "6  _c6      Integral           1.0                             True\n",
       "7  _c7      Integral           1.0                             True\n",
       "8  _c8      Integral           1.0                             True\n",
       "9  _c9      Integral           1.0                             True"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constraints_df = pd.io.json.json_normalize(\n",
    "    baseline_job.suggested_constraints().body_dict[\"features\"]\n",
    ")\n",
    "constraints_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf89bdfa-87a8-4a23-a299-0a303bbd9bcd",
   "metadata": {},
   "source": [
    "### Create a monitoring schedule\n",
    "With a monitoring schedule, SageMaker launches processing jobs at a specified frequency to analyze the data collected during a given period. SageMaker provides a [built-in container](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-pre-built-container.html) for performing analysis on tabular datasets. In the processing job, SageMaker compares the dataset for the current analysis with the baseline statistics and constraints and generates a violations report. In addition, CloudWatch metrics are emitted for each data feature under analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "d179ca01-f71e-4544-9ebb-daa61b74d866",
   "metadata": {},
   "outputs": [],
   "source": [
    "mon_schedule_name = \"from-idea-to-prod-monitor-schedule-\" + strftime(\n",
    "    \"%Y-%m-%d-%H-%M-%S\", gmtime()\n",
    ")\n",
    "\n",
    "data_monitor.create_monitoring_schedule(\n",
    "    monitor_schedule_name=mon_schedule_name,\n",
    "    endpoint_input=predictor.endpoint_name,\n",
    "    # record_preprocessor_script=pre_processor_script,\n",
    "    # post_analytics_processor_script=s3_code_postprocessor_uri,\n",
    "    output_s3_uri=reports_s3_url,\n",
    "    statistics=data_monitor.baseline_statistics(),\n",
    "    constraints=data_monitor.suggested_constraints(),\n",
    "    schedule_cron_expression=CronExpressionGenerator.hourly(),\n",
    "    enable_cloudwatch_metrics=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4a44fa-2ebf-4cf4-b34f-f72aeba5837a",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_endpoint_traffic(predictor, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "e98be4d2-0bcf-476a-a9e5-f710b2ecb0f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schedule status: Scheduled\n"
     ]
    }
   ],
   "source": [
    "desc_schedule_result = data_monitor.describe_schedule()\n",
    "print(\"Schedule status: {}\".format(desc_schedule_result[\"MonitoringScheduleStatus\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e46a76-d556-4d75-8b38-454fba95d419",
   "metadata": {},
   "source": [
    "### List schedule executions\n",
    "Youe created a hourly schedule above that begins executions on the hour (plus 0-20 min buffer. You will have to wait till the clock hit the hour. You can also change the schedule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "10d6b282-0949-441c-b0c7-e55ef9ff7a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No executions found for schedule. monitoring_schedule_name: from-idea-to-prod-monitor-schedule-2022-09-28-09-04-36\n"
     ]
    }
   ],
   "source": [
    "mon_executions = data_monitor.list_executions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f301094d-8039-42a0-b17d-5539d26a7c87",
   "metadata": {},
   "source": [
    "###Â View a monitoring job execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "a5d60781-821c-43c2-963b-9aab79c23e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No executions found\n"
     ]
    }
   ],
   "source": [
    "if len(mon_executions):\n",
    "    latest_execution = mon_executions[-1]  # get the latest execution\n",
    "    latest_execution.wait(logs=False)\n",
    "\n",
    "    print(\"Latest execution status: {}\".format(latest_execution.describe()[\"ProcessingJobStatus\"]))\n",
    "    print(\"Latest execution result: {}\".format(latest_execution.describe()[\"ExitMessage\"]))\n",
    "\n",
    "    latest_job = latest_execution.describe()\n",
    "    if latest_job[\"ProcessingJobStatus\"] != \"Completed\":\n",
    "        print(\"No completed executions to inspect further\")\n",
    "    else:\n",
    "        report_uri = latest_execution.output.destination\n",
    "        print(f\"Report Uri: {report_uri}\")\n",
    "else:\n",
    "    print(\"No executions found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba1d859-3753-49ea-ad78-d18f0b5a8bec",
   "metadata": {},
   "source": [
    "### View a violation report\n",
    "Model monitor outputs any violations compared to the baseline to a violation report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "2863de7d-22fc-467e-958b-d76dbb3e6d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 ls {reports_s3_url}/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "7e31de1c-77b3-4992-a2ab-237367c96340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No executions found for schedule. monitoring_schedule_name: from-idea-to-prod-monitor-schedule-2022-09-28-09-04-36\n",
      "No executions found for schedule. monitoring_schedule_name: from-idea-to-prod-monitor-schedule-2022-09-28-09-04-36\n"
     ]
    }
   ],
   "source": [
    "violations = data_monitor.latest_monitoring_constraint_violations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "5e9773b1-0f77-48f7-8090-7dcacfc0f15c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No violations report found\n"
     ]
    }
   ],
   "source": [
    "if violations:\n",
    "    pd.set_option(\"display.max_colwidth\", None)\n",
    "    constraints_df = pd.io.json.json_normalize(violations.body_dict[\"violations\"])\n",
    "    constraints_df.head(10)\n",
    "else:\n",
    "    print(\"No violations report found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2669f3-a09b-4ca8-9a17-a706239f16c4",
   "metadata": {},
   "source": [
    "## Model monitor - monitor model quality\n",
    "Model quality monitoring jobs monitor the performance of a model by comparing the predictions that the model makes with the actual ground truth labels that the model attempts to predict. To do this, model quality monitoring merges data that is captured from real-time inference with actual labels that you store in an Amazon S3 bucket, and then compares the predictions with the actual labels.\n",
    "\n",
    "Model quality monitoring follows the same steps as data quality monitoring, but adds the additional step of merging the actual labels from Amazon S3 with the predictions captured from the real-time inference endpoint.\n",
    "\n",
    "To monitor model quality, follow these steps:\n",
    "1. Enable [data capture](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-data-capture.html)\n",
    "1. [Create a baseline](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-model-quality-baseline.html). A baseline job compares predictions from the model with ground truth labels in a baseline dataset\n",
    "1. [Schedule monitoring jobs](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-model-quality-schedule.html)\n",
    "1. [Ingest ground truth labels](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-model-quality-merge.html) that model monitor merges with captured prediction data from real-time inference endpoint\n",
    "1. [Intepret the results](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-interpreting-results.html)\n",
    "1. [Integrate model quality monitoring](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-model-quality-cw.html) with Amazon CloudWatch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59071f22-f07e-446e-834e-f7bc2d44f40b",
   "metadata": {},
   "source": [
    "## Additional monitoring\n",
    "Additionally to data and model quality monitoring with Model Monitor, you can use Amazon SageMaker Clarify to:\n",
    "- [Monitor bias drift](https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-model-monitor-bias-drift.html)\n",
    "- [Monitor feature attribution drift](https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-model-monitor-feature-attribution-drift.html)\n",
    "\n",
    "Refer to a sample notebook [Monitoring bias drift and feature attribution drift Amazon SageMaker Clarify](https://sagemaker-examples.readthedocs.io/en/latest/sagemaker_model_monitor/fairness_and_explainability/SageMaker-Model-Monitor-Fairness-and-Explainability.html) for a hands-on example and more details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2057c12f-1aae-4087-8930-4150543ff38a",
   "metadata": {},
   "source": [
    "## Use SageMaker Studio for data and model monitoring\n",
    "You can use Studio UX to enable and configure data and model monitoring and to visualize results. You can view the details of any monitoring job run, and you can create charts that show the baseline and captured values for any metric that the monitoring job calculates.\n",
    "\n",
    "Navigate to **SageMaker resources** to the left side bar and choose **Endpoints** in the drop-down menu. Double-click on an endpoint for which you would like to configure the model monitoring:\n",
    "\n",
    "<img src=\"img/endpoints.png\" width=\"400\"/>\n",
    "\n",
    "In the displayed **Endpoint details** tab you can configure data and model monitoring:\n",
    "\n",
    "![](img/model-monitoring-ux.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ed36be-5547-481a-90c4-3d8647db0957",
   "metadata": {},
   "source": [
    "## Clean-up resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "029e36c7-d86d-4b6a-ae06-6884fbfe3a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stopping Monitoring Schedule with name: from-idea-to-prod-monitor-schedule-2022-09-28-08-56-21\n",
      "\n",
      "Deleting Monitoring Schedule with name: from-idea-to-prod-monitor-schedule-2022-09-28-08-56-21\n"
     ]
    }
   ],
   "source": [
    "data_monitor.stop_monitoring_schedule()\n",
    "data_monitor.delete_monitoring_schedule()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3fc9ec-caa3-4adf-9b9a-66bf6ba3ec71",
   "metadata": {},
   "source": [
    "### Final clean-up\n",
    "This is the last notebook in this workshop. If you are finished with exploration, to avoid charges on your AWS account, run the [clean-up notebook](99-clean-up.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea675fa-2d8f-4b15-b9cd-91104a96edee",
   "metadata": {},
   "source": [
    "## Further development ideas for your real-world projects\n",
    "- Add [visualizations](https://sagemaker-examples.readthedocs.io/en/latest/sagemaker_model_monitor/visualization/SageMaker-Model-Monitor-Visualize.html) for model monitoring reports\n",
    "- Add data baselining, explainability report generation, and bias report to the model building pipeline\n",
    "- Implement [model quality monitoring](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-model-quality.html)\n",
    "- Try different inference options such as [serverless](https://docs.aws.amazon.com/sagemaker/latest/dg/serverless-endpoints.html) or [asynchronous](https://docs.aws.amazon.com/sagemaker/latest/dg/async-inference.html) inference\n",
    "- Address security considerations for your ML environment and solutions. Start with the developer guide [Security in Amazon SageMaker](https://docs.aws.amazon.com/sagemaker/latest/dg/security.html)\n",
    "- Implement [deployment guardrails](https://docs.aws.amazon.com/sagemaker/latest/dg/deployment-guardrails.html) to control how to update your models in production"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b9b6df-94d1-49ee-a21b-42b153d3fe4c",
   "metadata": {},
   "source": [
    "## Additional resources\n",
    "- [Monitor models for data and model quality, bias, and explainability](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor.html)\n",
    "- [Monitor data quality](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-data-quality.html)\n",
    "- [Model Monitor visualizations](https://sagemaker-examples.readthedocs.io/en/latest/sagemaker_model_monitor/visualization/SageMaker-Model-Monitor-Visualize.html)\n",
    "- [Monitor Amazon SageMaker](https://docs.aws.amazon.com/sagemaker/latest/dg/monitoring-overview.html)\n",
    "- [Monitoring a Model in Production](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-model-monitor.html)\n",
    "- [Security in Amazon SageMakerv](https://docs.aws.amazon.com/sagemaker/latest/dg/security.html)\n",
    "- [Deployment guardrails](https://docs.aws.amazon.com/sagemaker/latest/dg/deployment-guardrails.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee54a7b1-0e4a-424c-9283-07c62c1a4e2a",
   "metadata": {},
   "source": [
    "# Shutdown kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9cc068d-e111-46db-aaef-01fc30fa5069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<p><b>Shutting down your kernel for this notebook to release resources.</b></p>\n",
       "<button class=\"sm-command-button\" data-commandlinker-command=\"kernelmenu:shutdown\" style=\"display:none;\">Shutdown Kernel</button>\n",
       "        \n",
       "<script>\n",
       "try {\n",
       "    els = document.getElementsByClassName(\"sm-command-button\");\n",
       "    els[0].click();\n",
       "}\n",
       "catch(err) {\n",
       "    // NoOp\n",
       "}    \n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "\n",
    "<p><b>Shutting down your kernel for this notebook to release resources.</b></p>\n",
    "<button class=\"sm-command-button\" data-commandlinker-command=\"kernelmenu:shutdown\" style=\"display:none;\">Shutdown Kernel</button>\n",
    "        \n",
    "<script>\n",
    "try {\n",
    "    els = document.getElementsByClassName(\"sm-command-button\");\n",
    "    els[0].click();\n",
    "}\n",
    "catch(err) {\n",
    "    // NoOp\n",
    "}    \n",
    "</script>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c5fa65-6e71-4e91-9449-0ea57a5261c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
