{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0551f521-eaea-4e5c-a9a9-60a93aaa018e",
   "metadata": {},
   "source": [
    "# Step 6: Add data monitoring\n",
    "After executing five previous notebooks, you have a production-ready solution with automated model building and model deployment CI/CD pipelines.\n",
    "This notebook adds continuous monitoring of the data quality in real-time. [Amazon SageMaker model monitor](https://aws.amazon.com/sagemaker/model-monitor/) enables you to set up an automated alert triggering system when there are deviations in the data and model quality, such as data drift and anomalies.\n",
    "\n",
    "![](img/six-steps-6.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcada1a-d8a5-4f5a-9d2b-e8da352aa3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install jsonlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2681315-b19c-4e97-a49e-21f04efb6bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker \n",
    "import json\n",
    "import jsonlines\n",
    "from sagemaker.model_monitor import DataCaptureConfig\n",
    "from sagemaker.predictor import Predictor\n",
    "import time\n",
    "from time import gmtime, strftime\n",
    "import uuid\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sagemaker.model_monitor import DefaultModelMonitor\n",
    "from sagemaker.model_monitor.dataset_format import DatasetFormat\n",
    "from sagemaker.model_monitor import CronExpressionGenerator\n",
    "from utils.monitoring_utils import run_model_monitor_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b8d993-1c33-40ad-96ee-7340edadcc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = boto3.client(\"sagemaker\")\n",
    "s3 = boto3.client(\"s3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2fb029-39b2-48ee-a3d6-38f1a42f25ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r \n",
    "\n",
    "%store\n",
    "\n",
    "try:\n",
    "    initialized\n",
    "except NameError:\n",
    "    print(\"+++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    print(\"[ERROR] YOU HAVE TO RUN 00-start-here notebook   \")\n",
    "    print(\"+++++++++++++++++++++++++++++++++++++++++++++++++\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ae4a24-1294-4bda-8f68-4e811025932d",
   "metadata": {},
   "source": [
    "## How model monitor works\n",
    "Amazon SageMaker Model Monitor automatically monitors ML models in production and notifies you when quality issues arise. Model Monitor uses rules to detect drift in your models and data and alerts you when it happens. The following figure shows how this process works.\n",
    "\n",
    "![](img/model-monitor.png)\n",
    "\n",
    "The process for setting up the data monitoring:\n",
    "1. Enable the endpoint to capture data from incoming requests to a trained ML model and the resulting model predictions\n",
    "2. Create a baseline from the dataset that was used to train the model. The baseline computes metrics and suggests constraints for the metrics. Real-time predictions from your model are compared to the constraints, and are reported as violations if they are outside the constrained values\n",
    "3. Create a monitoring schedule specifying what data to collect, how often to collect it, how to analyze it, and which reports to produce\n",
    "4. Inspect the reports, which compare the latest data with the baseline, and watch for any violations reported and for metrics and notifications from Amazon CloudWatch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f977d10-057f-4d9f-85ba-17b5dd7ebff6",
   "metadata": {},
   "source": [
    "## Real-time inference data capture from a SageMaker endpoint\n",
    "To work with the model monitor, use the existing endpoints deployed by the deployment pipeline in the step 5 notebook.\n",
    "\n",
    "The model deployment MLOps project implemented in the step 5 notebook contains a data capture configuration for the deployed endpoints. If you clone the project's code repository to the Studio file system, you can see the project files.\n",
    "\n",
    "The CloudFormation deployment template `endpoint-config-template.yml` enables data capture for the endpoint configuration:\n",
    "```yaml\n",
    "EndpointConfig:\n",
    "    Type: AWS::SageMaker::EndpointConfig\n",
    "    Properties:\n",
    "      ProductionVariants:\n",
    "        - InitialInstanceCount: !Ref EndpointInstanceCount\n",
    "          InitialVariantWeight: 1.0\n",
    "          InstanceType: !Ref EndpointInstanceType\n",
    "          ModelName: !GetAtt Model.ModelName\n",
    "          VariantName: AllTraffic\n",
    "      DataCaptureConfig:\n",
    "          EnableCapture: !Ref EnableDataCapture \n",
    "          InitialSamplingPercentage: !Ref SamplingPercentage\n",
    "          DestinationS3Uri: !Ref DataCaptureUploadPath\n",
    "          CaptureOptions:\n",
    "            - CaptureMode: Input\n",
    "            - CaptureMode: Output\n",
    "          CaptureContentTypeHeader:\n",
    "            CsvContentTypes:\n",
    "              - \"text/csv\"\n",
    "```\n",
    "\n",
    "The configuration files `prod-config.json` and `staging-config.json` provide the actual values for `EnableCapture`, `InitialSamplingPercentage`, and `DestinationS3Uri`:\n",
    "```json\n",
    "{\n",
    "  \"Parameters\": {\n",
    "    \"StageName\": \"prod\",\n",
    "    \"EndpointInstanceCount\": \"1\",\n",
    "    \"EndpointInstanceType\": \"ml.m5.large\",\n",
    "    \"SamplingPercentage\": \"80\",\n",
    "    \"EnableDataCapture\": \"true\"\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "Let's check the endpoint configuration and see how data capture is confgured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70bcd2e-95f9-4dfd-9830-a48b579c7c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ep in sm.list_endpoints(StatusEquals=\"InService\")[\"Endpoints\"]:\n",
    "    print(f\"Data capture configuration for {ep['EndpointName']}:\")\n",
    "    print(f\"{json.dumps(sm.describe_endpoint(EndpointName=ep['EndpointName'])['DataCaptureConfig'], indent=2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a891b9fe-37a3-44fa-a1d6-2fe94262410c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the configuration for a specific endpoint name\n",
    "endpoint_name = \"model-deploy-30-21-35-29-staging\" # USE YOUR ENDPOINT NAME\n",
    "data_capture_s3_url = sm.describe_endpoint(EndpointName=endpoint_name)['DataCaptureConfig']['DestinationS3Uri']\n",
    "data_capture_bucket = data_capture_s3_url.split('/')[2]\n",
    "data_capture_prefix = '/'.join(data_capture_s3_url.split('/')[3:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cbc4f7-ccd9-4399-8ffe-a736e2cc6cc4",
   "metadata": {},
   "source": [
    "### Define helper functions\n",
    "Define some helper functions with code snippets that you're going to use throughout this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7da46e-d957-4351-a804-2724cd0c3869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print progress bar\n",
    "def printProgressBar (iteration, total, prefix = '', suffix = '', decimals = 1, length = 100, fill = '█', printEnd = \"\\r\"):\n",
    "    percent = (\"{0:.\" + str(decimals) + \"f}\").format(100 * (iteration / float(total)))\n",
    "    filledLength = int(length * iteration // total)\n",
    "    bar = fill * filledLength + '-' * (length - filledLength)\n",
    "    print(f'\\r{prefix} |{bar}| {percent}% {suffix}', end = printEnd)\n",
    "    # Print New Line on Complete\n",
    "    if iteration == total: \n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d880ebc0-f728-42e0-82fa-84a8daddda87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send data to the endpoint\n",
    "def generate_endpoint_traffic(predictor, data):\n",
    "    l = len(data)\n",
    "    print(f\"Sending {l} vectors to the endpoint\")\n",
    "    for i in range(0,l):\n",
    "        predictions = np.array(predictor.predict(data.iloc[i].values), dtype=float).squeeze()\n",
    "        time.sleep(0.001)\n",
    "        printProgressBar(i + 1, l, prefix = 'Progress:', suffix = 'Complete', length = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9297bbfc-8360-42a1-bc2a-2932372aee8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get S3 url for the latest captured data\n",
    "def get_latest_data_capture_s3_url(bucket, prefix):\n",
    "    try:\n",
    "        capture_files = [\n",
    "            capture_file.get(\"Key\") \n",
    "            for capture_file in s3.list_objects(Bucket=bucket, Prefix=prefix).get(\"Contents\")\n",
    "        ]\n",
    "\n",
    "        latest_data_capture_s3_url = f\"s3://{bucket}/{'/'.join(capture_files[-1].split('/')[:-1])}\"\n",
    "\n",
    "        print(f\"Latest data capture S3 url: {latest_data_capture_s3_url}\")\n",
    "        \n",
    "        return latest_data_capture_s3_url\n",
    "    except TypeError:\n",
    "        print(f\"No data capture files found in s3://{bucket}/{prefix}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9921dd5-3a14-4354-9731-479b1088393e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get S3 url for the latest monitoring job output\n",
    "def get_latest_monitoring_report_s3_url(job_name):\n",
    "    monitor_job = sm.list_processing_jobs(\n",
    "        NameContains=job_name,\n",
    "        SortOrder='Descending',\n",
    "        MaxResults=2\n",
    "    )['ProcessingJobSummaries'][0]['ProcessingJobName']\n",
    "\n",
    "    monitoring_job_output_s3_url = sm.describe_processing_job(\n",
    "        ProcessingJobName=monitor_job\n",
    "    )['ProcessingOutputConfig']['Outputs'][0]['S3Output']['S3Uri']\n",
    "\n",
    "    print(f\"Latest monitoring report S3 url: {monitoring_job_output_s3_url}\")\n",
    "    \n",
    "    return monitoring_job_output_s3_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d571446-c518-4f34-8532-81fce2298091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper to load a json file from S3\n",
    "def load_json_from_file(file_s3_url):\n",
    "    bucket = file_s3_url.split('/')[2]\n",
    "    key = '/'.join(file_s3_url.split('/')[3:])\n",
    "    print(f\"Load JSON from: {bucket}/{key}\")\n",
    "    \n",
    "    return json.loads(\n",
    "        s3.get_object(Bucket=bucket, \n",
    "                      Key=key)[\"Body\"].read().decode(\"utf-8\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190e011d-ba01-43c8-8af9-959bb7835574",
   "metadata": {},
   "source": [
    "### Generate captured data\n",
    "You must send some data to an endpoint for inference to generate data capture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58229914-7fa6-4d5c-841b-2bbc32c6add5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = Predictor(\n",
    "    endpoint_name=endpoint_name, \n",
    "    serializer=sagemaker.serializers.CSVSerializer(),\n",
    "    deserializer=sagemaker.deserializers.CSVDeserializer()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4229045-c339-42ba-8116-f21d6d8ea3e6",
   "metadata": {},
   "source": [
    "Use test dataset prepared in the step 2 notebook (`test_x.csv`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652224c3-4121-41c1-9494-f4d8a287f2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = pd.read_csv(\"tmp/test_x.csv\", names=[f'_c{i}' for i in range(59)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b145f1-2e5d-49a2-a855-82375351eb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7266a4-a744-4339-9da1-e1b87a4144c9",
   "metadata": {},
   "source": [
    "Send the data to the endpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150cdd96-de42-4b63-9925-415097ecc680",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "generate_endpoint_traffic(predictor, test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1ca97e-2129-4371-9695-c08d3e46f11b",
   "metadata": {},
   "source": [
    "### View captured data\n",
    "Now list the data capture files stored in Amazon S3. The data is stored as `jsonl` an Amazon S3 path format is `s3://{data-capture-destination-s3-url}/{endpoint-name}/{variant-name}/yyyy/mm/dd/hh/filename.jsonl`.\n",
    "\n",
    "Wait until captured data appears in the Amazon S3 bucket, it may take several minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d0fd2a-65e6-48d2-ab50-2e6cf8597f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 ls {data_capture_s3_url} --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b6a4c5-09ae-464e-a24a-9c474e6ae10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "capture_files = [\n",
    "    capture_file.get(\"Key\") \n",
    "    for capture_file in s3.list_objects(Bucket=data_capture_bucket, Prefix=data_capture_prefix).get(\"Contents\")\n",
    "]\n",
    "print(\"Found data capture files:\")\n",
    "print(\"\\n \".join(capture_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bb593e-cc43-454d-8f75-40fcb795a466",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(capture_files) > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60ba1b4-8e39-4b1b-8f17-3253e6cb0a9b",
   "metadata": {},
   "source": [
    "Each inference request is captured in one line in the `jsonl` file. The line contains both the input and output merged together. In the example, you provided the ContentType as `text/csv` which is reflected in the `observedContentType` value. Also, you expose the encoding that you used to encode the input and output payloads in the capture format with the encoding value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb20f7b7-a2c5-4dd2-8629-04afa4484188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the last captured dataset to Studio's EFS\n",
    "!aws s3 cp s3://{data_capture_bucket}/{capture_files[-1]} ./tmp/datacapture.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ed0e8a-579e-4cb7-8a61-30a39c9140ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the jsonl object and show two first requests\n",
    "with jsonlines.open('./tmp/datacapture.jsonl') as reader:      \n",
    "    print(json.dumps(reader.read(), indent=2))\n",
    "    print(json.dumps(reader.read(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ada3476-3067-47e8-bcc1-f515972048c2",
   "metadata": {},
   "source": [
    "## Model monitor - monitor data quality\n",
    "In this example you learn how to setup data quality monitoring.\n",
    "\n",
    "To enable inference data quality monitoring and evaluation you must:\n",
    "1. Enable [data capture](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-data-capture.html)\n",
    "1. [Create a baseline](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-create-baseline.html) with which you compare the realtime traffic\n",
    "1. Once a baseline is ready, [schedule monitoring jobs](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-scheduling.html) to continously evaluate and compare against the baseline\n",
    "1. [See and interpret the results](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-interpreting-results.html) of monitoring jobs\n",
    "1. [Integrate data quality monitoring](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-interpreting-cloudwatch.html) with Amazon CloudWatch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84268bba-f44e-4cb4-a53f-67251253c1a4",
   "metadata": {},
   "source": [
    "### Create a baselining job with training dataset\n",
    "The whole dataset with which you trained and tested the model is usually a good baseline dataset. Note that the baseline dataset data schema and the inference dataset schema should exactly match (i.e. the number and order of the features).\n",
    "\n",
    "From the baseline dataset you can ask Amazon SageMaker to suggest a set of baseline _constraints_ and generate descriptive _statistics_ to explore the data. Model Monitor provides a [built-in container](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-pre-built-container.html) that provides the ability to suggest the constraints automatically for CSV and flat JSON input. This `sagemaker-model-monitor-analyzer` container also provides you with a range of model monitoring capabilities, including constraint validation against a baseline, and emitting Amazon CloudWatch metrics. This container is based on Spark and is built with [Deequ](https://github.com/awslabs/deequ). \n",
    "\n",
    "All column names in your baseline dataset must be compliant with Spark. For column names, use only lowercase characters, and _ as the only special character.\n",
    "\n",
    "Use the baseline dataset you created in the step 2 notebook data processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbaac6de-b3a9-4f4d-b6e2-2f2a66b86a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 ls {baseline_s3_url}/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632362d5-c4e0-4bf5-bca4-b4da6ad34377",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_results_s3_url = f\"{baseline_s3_url}/results\"\n",
    "reports_s3_url = f\"{baseline_s3_url}/reports\"\n",
    "baseline_dataset_uri = f\"{baseline_s3_url}/baseline.csv\"\n",
    "baseline_job_name = f\"from-idea-to-prod-processing-baselining-{strftime('%d-%H-%M-%S', gmtime())}-{str(uuid.uuid4())[:8]}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d49b158-9859-4053-8ec9-8f99577ed07e",
   "metadata": {},
   "source": [
    "Start a SageMaker projcessing job on the baseline data to profile data and suggest constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5443d53d-00e9-4320-9c72-1751fe796778",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_monitor = DefaultModelMonitor(\n",
    "    role=sm_role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    volume_size_in_gb=20,\n",
    "    max_runtime_in_seconds=3600,\n",
    ")\n",
    "\n",
    "data_monitor.suggest_baseline(\n",
    "    baseline_dataset=baseline_dataset_uri,\n",
    "    dataset_format=DatasetFormat.csv(header=False),\n",
    "    output_s3_uri=baseline_results_s3_url,\n",
    "    wait=True,\n",
    "    logs=False,\n",
    "    job_name=baseline_job_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29e9063-5fb6-4bda-86c1-d33b2b0ca10b",
   "metadata": {},
   "source": [
    "### See the generated statistics and constraints\n",
    "After the baselining jobs finished, it saves the baseline statistics to the `statistics.json` file and the suggested baseline constraints to the `constraints.json` file in the location you specify with `output_s3_uri`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff77ab21-f595-417e-a880-a3cb73be87c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 ls {baseline_results_s3_url}/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a377fca9-436d-45cd-818c-4a8c88f84c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics_s3_url = f\"{baseline_results_s3_url}/statistics.json\"\n",
    "constraints_s3_url = f\"{baseline_results_s3_url}/constraints.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366806e0-fae7-41a1-8f67-a46ac297d9c1",
   "metadata": {},
   "source": [
    "Load the generated JSON as Pandas DataFrame and see the content of `statistics.json` and `constaints.json`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1f849c-8ca0-4c7f-a3a4-eac7b7553b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_job = data_monitor.latest_baselining_job\n",
    "statistics_df = pd.json_normalize(baseline_job.baseline_statistics().body_dict[\"features\"])\n",
    "statistics_df.head(59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdb5f66-da5c-477f-b66a-3997713404bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "constraints_df = pd.json_normalize(\n",
    "    baseline_job.suggested_constraints().body_dict[\"features\"]\n",
    ")\n",
    "constraints_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf40e47-2c22-4ca3-8fe1-02f428e5e0b8",
   "metadata": {},
   "source": [
    "For this dataset the baselining job suggest three constraints:\n",
    "1. DataType\n",
    "2. Completeness\n",
    "3. Is non-negative\n",
    "\n",
    "Additionally, the Model Monitor prebuilt container does missing and extra column check, baseline drift check, and categorical values check. Refer to [Developer Guide](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-interpreting-violations.html) for more details.\n",
    "\n",
    "In a real-world project you can add your own constraints the data must comply with.\n",
    "\n",
    "Next you schedule and run a monitoring job to validate incoming data against these constraints and statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf89bdfa-87a8-4a23-a299-0a303bbd9bcd",
   "metadata": {},
   "source": [
    "### Create a monitoring schedule\n",
    "With a monitoring schedule, SageMaker launches processing jobs at a specified frequency to analyze the data collected during a given period. SageMaker provides a [built-in container](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-pre-built-container.html) for performing analysis on tabular datasets. In the processing job, SageMaker compares the dataset for the current analysis with the baseline statistics and constraints and generates a violations report. In addition, CloudWatch metrics are emitted for each data feature under analysis.\n",
    "\n",
    "#### Implement custom record processing with a preprocessing script\n",
    "You can extend Model Monitor by providing a custom record preprocessing function. In this function you can implement your own filtering or preprocessing of every data record. For example, you can skip some records from analysis based on values or some event metadata. Refer to [Preprocessing and Postprocessing](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-pre-and-post-processing.html) documentation for more details and examples.\n",
    "\n",
    "When you created a monitoring baseline, you used the baseline dataset with all features but without the label. The Model Monitor by default concatenates model input and output, resulting in a dataset which contains all features plus the label. If you don't preprocess records before passing them to Model Monitor, the number of columns in the baseline dataset won't match the number of columns in the record, and Model Monitor will report a `extra_column_check` violation. To avoid this situation, you need either to include the label column in the baselining or remove model output from the monitored records. This notebook uses the latter approach and provides a preprocessing script that returns only input data without the label.\n",
    "\n",
    "For another example of custom preprocessing see the blog post [Design a compelling record filtering method with Amazon SageMaker Model Monitor](https://aws.amazon.com/blogs/machine-learning/design-a-compelling-record-filtering-method-with-amazon-sagemaker-model-monitor/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d83eb20-f98c-4579-9de7-a3147cb7c15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pygmentize ./record_preprocessor.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a8a258-18ee-495f-aa97-e1f61890619c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the preprocessing script to S3\n",
    "record_preprocessor_s3_url = f\"s3://{bucket_name}/{bucket_prefix}/code\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cca5a8-7af8-44f0-b4a4-33daf44e9468",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp ./record_preprocessor.py {record_preprocessor_s3_url}/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d179ca01-f71e-4544-9ebb-daa61b74d866",
   "metadata": {},
   "outputs": [],
   "source": [
    "mon_schedule_name = \"from-idea-to-prod-monitor-schedule-\" + strftime(\n",
    "    \"%Y-%m-%d-%H-%M-%S\", gmtime()\n",
    ")\n",
    "\n",
    "data_monitor.create_monitoring_schedule(\n",
    "    monitor_schedule_name=mon_schedule_name,\n",
    "    endpoint_input=predictor.endpoint_name,\n",
    "    record_preprocessor_script=f\"{record_preprocessor_s3_url}/record_preprocessor.py\",\n",
    "    # post_analytics_processor_script=s3_code_postprocessor_uri,\n",
    "    output_s3_uri=reports_s3_url,\n",
    "    statistics=data_monitor.baseline_statistics(),\n",
    "    constraints=data_monitor.suggested_constraints(),\n",
    "    schedule_cron_expression=CronExpressionGenerator.hourly(),\n",
    "    enable_cloudwatch_metrics=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98be4d2-0bcf-476a-a9e5-f710b2ecb0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_schedule_result = data_monitor.describe_schedule()\n",
    "print(\"Schedule status: {}\".format(desc_schedule_result[\"MonitoringScheduleStatus\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0597276a-420c-457d-a545-dcf7378c4234",
   "metadata": {},
   "source": [
    "### Generate compliant traffic\n",
    "Generate traffic that won't trigger any violations. Use the `test_x.csv` dataset to send requests to the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4a44fa-2ebf-4cf4-b34f-f72aeba5837a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "generate_endpoint_traffic(predictor, test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e2001d-62ed-465f-b273-4c7ce16fa39f",
   "metadata": {},
   "source": [
    "### See the captured data\n",
    "List captured data files under `data_capture_s3_url`. Wait couple of minutes before the captured data appears in the Amazon S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42cc853-a4d1-43b4-947a-06b0a7d9880f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 ls {data_capture_s3_url} --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4200659a-542c-4de6-8b23-ba98f2c81dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!aws s3 rm {data_capture_s3_url} --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b7477a-d418-48fb-83b1-f72830644d92",
   "metadata": {},
   "source": [
    "### Launch a manual monitoring job\n",
    "You can launch a monitoring job manually and don't wait until a configured scheduled execution. Since the Model Monitor uses a [built-in container](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-pre-built-container.html) and a SageMaker [processing job](https://docs.aws.amazon.com/sagemaker/latest/dg/processing-job.html) to run analysis of the captured data, you can manually configure and run a monitoring job. \n",
    "\n",
    "This [repository](https://github.com/aws-samples/reinvent2019-aim362-sagemaker-debugger-model-monitor/tree/master/02_deploy_and_monitor) contains an implementation of a helper function to manually run a monitoring job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd005eb-b66b-4650-a702-311549cb5b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pygmentize ./utils/monitoring_utils.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f50e08-ab18-48e2-9241-ce73d4643c68",
   "metadata": {},
   "source": [
    "Get an S3 url for the latest captured data files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdb2413-0dd4-499d-8076-23435b1e4a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_data_capture_s3_url = get_latest_data_capture_s3_url(data_capture_bucket, data_capture_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1e975f-83ea-4cf1-8883-71b2875a7432",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Data capture path: {latest_data_capture_s3_url}\")\n",
    "print(f\"Baseline statistics file: {statistics_s3_url}\")\n",
    "print(f\"Baseline constraints file: {constraints_s3_url}\")\n",
    "print(f\"Data monitor report output path: {reports_s3_url}\")\n",
    "print(f\"Record preprocessor script path: {record_preprocessor_s3_url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45d63e6-ec35-4568-a20f-6f64de9490cb",
   "metadata": {},
   "source": [
    "Run a monitoring job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb8dbcd-61c9-4b7e-8d15-7c3efbd40601",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.monitoring_utils.run_model_monitor_job(\n",
    "    region=region,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    role=sm_role,\n",
    "    data_capture_path=latest_data_capture_s3_url,\n",
    "    statistics_path=statistics_s3_url,\n",
    "    constraints_path=constraints_s3_url,\n",
    "    reports_path=reports_s3_url,\n",
    "    instance_count=1,\n",
    "    preprocessor_path=f\"{record_preprocessor_s3_url}/record_preprocessor.py\",\n",
    "    postprocessor_path=None,\n",
    "    publish_cloudwatch_metrics=\"Disabled\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715c8ff4-e24d-49a9-a212-be635fbff216",
   "metadata": {},
   "source": [
    "### See the monitoring job output\n",
    "Let's check what reports the monitoring job generated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30aaec02-b385-4c96-9db5-4454d9916db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_monitoring_job_output_s3_url = get_latest_monitoring_report_s3_rul(\"sagemaker-model-monitor-analyzer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c66b5f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedfef20-9df8-4969-ab18-8606a325c28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 ls {manual_monitoring_job_output_s3_url}/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3770d68a-42a8-4f60-be4d-b424f52d16f0",
   "metadata": {},
   "source": [
    "Load the monitoring reports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c876d5a1-54ad-409e-acd5-2d648b386413",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_json(f\"{manual_monitoring_job_output_s3_url}/constraint_violations.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266d95b7-8c3b-4bdf-a820-77d884c43c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics = load_json_from_file(f\"{manual_monitoring_job_output_s3_url}/statistics.json\")\n",
    "constraints = load_json_from_file(f\"{manual_monitoring_job_output_s3_url}/constraints.json\")\n",
    "\n",
    "print(f\"Records processed: {statistics['dataset']['item_count']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f572e5ac-3519-48b9-b4c9-e611c8e71d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.json_normalize(statistics[\"features\"]).head(59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f99d6e-b261-4f89-be20-dacde27ae18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.json_normalize(constraints[\"features\"]).head(59)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d567b72b-805b-43e7-b926-db97015d00f4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Generate non-compliant traffic\n",
    "Now generate traffic that will trigger the violation in the model monitor data quality check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fa53a9-fcf8-42a3-a4a5-b0460d1e0919",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_compliant_pd = test_x.copy()\n",
    "non_compliant_pd.iloc[:,0] = -100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9907bf99-f24e-4d86-ad2d-a87433ca43c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_compliant_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef3d752-cf16-4614-94fd-90c09190b9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove previous data capture with compliant traffic\n",
    "latest_data_capture_s3_url = get_latest_data_capture_s3_url(data_capture_bucket, data_capture_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47f60b6-b24d-4f32-88d3-b69d75d8ab67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment the next line to remove the previous data capture files\n",
    "#!aws s3 rm {latest_data_capture_s3_url} --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df19f6a-f6e2-4c75-94e7-fb7211faa557",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "generate_endpoint_traffic(predictor, non_compliant_pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c348cd59-9925-4d29-97ae-e90baef5e3f6",
   "metadata": {},
   "source": [
    "### See the captured data\n",
    "List captured data files under `data_capture_s3_url`. Wait couple of minutes before the captured data appears in the Amazon S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b729c49-8118-4229-a260-6fcdf455b29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 ls {data_capture_s3_url} --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b59387d-d96f-47c6-b058-3a4d7168c4ab",
   "metadata": {},
   "source": [
    "### Launch a manual monitoring job\n",
    "Let's run a manual monitoring job again to analyze the capture data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4615cb98-2c7d-4656-b714-18f5f30a5dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_data_capture_s3_url = get_latest_data_capture_s3_url(data_capture_bucket, data_capture_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97db3837-3b58-4c7d-85b5-495bce6f7d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.monitoring_utils.run_model_monitor_job(\n",
    "    region=region,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    role=sm_role,\n",
    "    data_capture_path=latest_data_capture_s3_url,\n",
    "    statistics_path=statistics_s3_url,\n",
    "    constraints_path=constraints_s3_url,\n",
    "    reports_path=reports_s3_url,\n",
    "    instance_count=1,\n",
    "    preprocessor_path=f\"{record_preprocessor_s3_url}/record_preprocessor.py\",\n",
    "    postprocessor_path=None,\n",
    "    publish_cloudwatch_metrics=\"Disabled\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1b92c6-5a1f-4908-bb95-df4059111ef4",
   "metadata": {},
   "source": [
    "### See the monitoring job output\n",
    "Let's check what reports the monitoring job generated. Since you send non-compliant data to the endpoint, you must see a violation report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01e44ce-e861-4113-90e7-c0281511447e",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_monitoring_job_output_s3_url = get_latest_monitoring_report_s3_rul(\"sagemaker-model-monitor-analyzer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fe74d1-e7d0-4978-ae6f-7907058ac68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 ls {manual_monitoring_job_output_s3_url}/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bccea03-786f-4dfc-902e-60568d09131a",
   "metadata": {},
   "source": [
    "Load the monitoring reports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1d51d6-8ba8-4ecc-a437-70a76e2ec172",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_json(f\"{manual_monitoring_job_output_s3_url}/constraint_violations.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ff077d-7ad3-4648-890f-7c0cd60a51a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics = load_json_from_file(f\"{manual_monitoring_job_output_s3_url}/statistics.json\")\n",
    "constraints = load_json_from_file(f\"{manual_monitoring_job_output_s3_url}/constraints.json\")\n",
    "\n",
    "print(f\"Records processed: {statistics['dataset']['item_count']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74aac0c2-374f-4f88-b114-19419025ac90",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.json_normalize(statistics[\"features\"]).head(59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f56dec7-dd76-419a-ac0f-db7c18234044",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.json_normalize(constraints[\"features\"]).head(59)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e46a76-d556-4d75-8b38-454fba95d419",
   "metadata": {},
   "source": [
    "### List schedule executions and monitoring reports\n",
    "You created a hourly schedule above that begins executions on the hour plus 0-20 min buffer. You will have to wait till the clock hit the hour. You can also change the schedule.\n",
    "\n",
    "This section demonstrates how to work with scheduled monitoring job execution. Python SDK [`DefaultModelMonitor`](https://sagemaker.readthedocs.io/en/stable/api/inference/model_monitor.html#sagemaker.model_monitor.model_monitoring.DefaultModelMonitor) implements helper methods to load and see the executions and monitoring reports."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f301094d-8039-42a0-b17d-5539d26a7c87",
   "metadata": {},
   "source": [
    "List executions and view a monitoring job details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d60781-821c-43c2-963b-9aab79c23e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "mon_executions = data_monitor.list_executions()\n",
    "\n",
    "if len(mon_executions):\n",
    "    latest_execution = mon_executions[-1]  # get the latest execution\n",
    "    latest_execution.wait(logs=False)\n",
    "\n",
    "    print(f\"Latest execution status: {latest_execution.describe()['ProcessingJobStatus']}\")\n",
    "    print(f\"Latest execution result: {latest_execution.describe()['ExitMessage']}\")\n",
    "\n",
    "    latest_job = latest_execution.describe()\n",
    "    if latest_job[\"ProcessingJobStatus\"] != \"Completed\":\n",
    "        print(\"No completed executions to inspect further\")\n",
    "    else:\n",
    "        report_uri = latest_execution.output.destination\n",
    "        print(f\"Report Uri: {report_uri}\")\n",
    "else:\n",
    "    print(\"No executions found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c119d4c3-fca4-4146-9079-483f15df8b18",
   "metadata": {},
   "source": [
    "See details about the latest scheduled monitoring execution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef16c05-4f41-487d-9e4b-fb40780338e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mon_executions[-1].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898dc7bb-364f-40c0-9181-9130fe2ec9d7",
   "metadata": {},
   "source": [
    "Get the latest execution statistics and constraints as objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9a5590-5fc9-4fd5-a094-33c5fc2c996d",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_execution_statistics = mon_executions[-1].statistics()\n",
    "last_execution_violations = mon_executions[-1].constraint_violations()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdeae78-a391-4f36-a781-95024b7bc9c1",
   "metadata": {},
   "source": [
    "Load reports into Pandas DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f37f50-6aed-4489-b50d-a8476ace0ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.json_normalize(last_execution_statistics.body_dict[\"features\"]).head(59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec57f3eb-4fb1-4a0d-ba61-9f4aef53298e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.json_normalize(last_execution_violations.body_dict[\"violations\"]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59e3043-775a-4d6b-8890-136095c28a85",
   "metadata": {},
   "source": [
    "See the baseline and the latest data profiling statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0fc10e-fc5a-46c4-8690-372864c8b03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.json_normalize(data_monitor.baseline_statistics().body_dict[\"features\"]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a18ba4-5a16-4026-a3aa-794f3a2410b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.json_normalize(data_monitor.latest_monitoring_statistics().body_dict[\"features\"]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba1d859-3753-49ea-ad78-d18f0b5a8bec",
   "metadata": {},
   "source": [
    "#### View a violation report\n",
    "Model monitor outputs any violations compared to the baseline to a violation report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2863de7d-22fc-467e-958b-d76dbb3e6d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 ls {reports_s3_url}/ --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e31de1c-77b3-4992-a2ab-237367c96340",
   "metadata": {},
   "outputs": [],
   "source": [
    "violations = data_monitor.latest_monitoring_constraint_violations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9773b1-0f77-48f7-8090-7dcacfc0f15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if violations:\n",
    "    pd.set_option(\"display.max_colwidth\", None)\n",
    "    violations_df = pd.json_normalize(violations.body_dict[\"violations\"])\n",
    "    violations_df.head()\n",
    "else:\n",
    "    print(\"No violations report found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e698a8-68ee-493f-bf1b-ffddea569762",
   "metadata": {},
   "outputs": [],
   "source": [
    "violations_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438f0f52-484c-4600-98e6-ea85e03f4507",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2669f3-a09b-4ca8-9a17-a706239f16c4",
   "metadata": {},
   "source": [
    "## Model monitor - monitor model quality\n",
    "Model quality monitoring jobs monitor the performance of a model by comparing the predictions that the model makes with the actual ground truth labels that the model attempts to predict. To do this, model quality monitoring merges data that is captured from real-time inference with actual labels that you store in an Amazon S3 bucket, and then compares the predictions with the actual labels.\n",
    "\n",
    "Model quality monitoring follows the same steps as data quality monitoring, but adds the additional step of merging the actual labels from Amazon S3 with the predictions captured from the real-time inference endpoint.\n",
    "\n",
    "To monitor model quality, follow these steps:\n",
    "1. Enable [data capture](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-data-capture.html)\n",
    "1. [Create a baseline](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-model-quality-baseline.html). A baseline job compares predictions from the model with ground truth labels in a baseline dataset\n",
    "1. [Schedule monitoring jobs](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-model-quality-schedule.html)\n",
    "1. [Ingest ground truth labels](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-model-quality-merge.html) that model monitor merges with captured prediction data from real-time inference endpoint\n",
    "1. [Intepret the results](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-interpreting-results.html)\n",
    "1. [Integrate model quality monitoring](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-model-quality-cw.html) with Amazon CloudWatch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59071f22-f07e-446e-834e-f7bc2d44f40b",
   "metadata": {},
   "source": [
    "## Additional monitoring\n",
    "Additionally to data and model quality monitoring with Model Monitor, you can use Amazon SageMaker Clarify to:\n",
    "- [Monitor bias drift](https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-model-monitor-bias-drift.html)\n",
    "- [Monitor feature attribution drift](https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-model-monitor-feature-attribution-drift.html)\n",
    "\n",
    "Refer to a sample notebook [Monitoring bias drift and feature attribution drift Amazon SageMaker Clarify](https://sagemaker-examples.readthedocs.io/en/latest/sagemaker_model_monitor/fairness_and_explainability/SageMaker-Model-Monitor-Fairness-and-Explainability.html) for a hands-on example and more details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2057c12f-1aae-4087-8930-4150543ff38a",
   "metadata": {},
   "source": [
    "## Use SageMaker Studio for data and model monitoring\n",
    "You can use Studio UX to enable and configure data and model monitoring and to visualize results. You can view the details of any monitoring job run, and you can create charts that show the baseline and captured values for any metric that the monitoring job calculates.\n",
    "\n",
    "Navigate to **SageMaker resources** to the left side bar and choose **Endpoints** in the drop-down menu. Double-click on an endpoint for which you would like to configure the model monitoring:\n",
    "\n",
    "<img src=\"img/endpoints.png\" width=\"400\"/>\n",
    "\n",
    "In the displayed **Endpoint details** tab you can configure data and model monitoring:\n",
    "\n",
    "![](img/model-monitoring-ux.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ed36be-5547-481a-90c4-3d8647db0957",
   "metadata": {},
   "source": [
    "## Clean-up resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029e36c7-d86d-4b6a-ae06-6884fbfe3a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_monitor.stop_monitoring_schedule()\n",
    "data_monitor.delete_monitoring_schedule()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3fc9ec-caa3-4adf-9b9a-66bf6ba3ec71",
   "metadata": {},
   "source": [
    "### Final clean-up\n",
    "This is the last notebook in this workshop. If you are finished with exploration, to avoid charges on your AWS account, run the [clean-up notebook](99-clean-up.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea675fa-2d8f-4b15-b9cd-91104a96edee",
   "metadata": {},
   "source": [
    "## Further development ideas for your real-world projects\n",
    "- Add [visualizations](https://sagemaker-examples.readthedocs.io/en/latest/sagemaker_model_monitor/visualization/SageMaker-Model-Monitor-Visualize.html) for model monitoring reports\n",
    "- Add data baselining, explainability report generation, and bias report to the model building pipeline\n",
    "- Implement [model quality monitoring](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-model-quality.html)\n",
    "- Try different inference options such as [serverless](https://docs.aws.amazon.com/sagemaker/latest/dg/serverless-endpoints.html) or [asynchronous](https://docs.aws.amazon.com/sagemaker/latest/dg/async-inference.html) inference\n",
    "- Address security considerations for your ML environment and solutions. Start with the developer guide [Security in Amazon SageMaker](https://docs.aws.amazon.com/sagemaker/latest/dg/security.html)\n",
    "- Implement [deployment guardrails](https://docs.aws.amazon.com/sagemaker/latest/dg/deployment-guardrails.html) to control how to update your models in production"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b9b6df-94d1-49ee-a21b-42b153d3fe4c",
   "metadata": {},
   "source": [
    "## Additional resources\n",
    "- [AmazonSageMaker Model Monitor: A System for Real-Time Insights into Deployed Machine Learning Models](https://assets.amazon.science/97/cc/8dc8526547859351f46d2710aba9/amazon-sagemaker-model-monitor-a-system-for-real-time-insights-into-deployed-machine-learning-models.pdf)\n",
    "- [Monitor models for data and model quality, bias, and explainability](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor.html)\n",
    "- [Monitor data quality](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-data-quality.html)\n",
    "- [Model Monitor visualizations](https://sagemaker-examples.readthedocs.io/en/latest/sagemaker_model_monitor/visualization/SageMaker-Model-Monitor-Visualize.html)\n",
    "- [Monitor Amazon SageMaker](https://docs.aws.amazon.com/sagemaker/latest/dg/monitoring-overview.html)\n",
    "- [Monitoring a Model in Production](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-model-monitor.html)\n",
    "- [ModelMonitor for batch transform jobs](https://aws.amazon.com/about-aws/whats-new/2022/10/amazon-sagemaker-model-monitor-batch-transform-jobs/)\n",
    "- [Security in Amazon SageMaker](https://docs.aws.amazon.com/sagemaker/latest/dg/security.html)\n",
    "- [Deployment guardrails](https://docs.aws.amazon.com/sagemaker/latest/dg/deployment-guardrails.html)\n",
    "- [Design a compelling record filtering method with Amazon SageMaker Model Monitor](https://aws.amazon.com/blogs/machine-learning/design-a-compelling-record-filtering-method-with-amazon-sagemaker-model-monitor/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee54a7b1-0e4a-424c-9283-07c62c1a4e2a",
   "metadata": {},
   "source": [
    "# Shutdown kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cc068d-e111-46db-aaef-01fc30fa5069",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "\n",
    "<p><b>Shutting down your kernel for this notebook to release resources.</b></p>\n",
    "<button class=\"sm-command-button\" data-commandlinker-command=\"kernelmenu:shutdown\" style=\"display:none;\">Shutdown Kernel</button>\n",
    "        \n",
    "<script>\n",
    "try {\n",
    "    els = document.getElementsByClassName(\"sm-command-button\");\n",
    "    els[0].click();\n",
    "}\n",
    "catch(err) {\n",
    "    // NoOp\n",
    "}    \n",
    "</script>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c5fa65-6e71-4e91-9449-0ea57a5261c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
