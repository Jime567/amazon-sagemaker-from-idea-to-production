{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6b39bb5-1408-45ab-af98-fa786ce6d55f",
   "metadata": {},
   "source": [
    "# Step 2: Use SageMaker processing and training jobs\n",
    "In this step we move data processing and model training into SageMaker containers and use SageMaker Python SDK to interact with SageMaker.\n",
    "\n",
    "![](img/six-steps-2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f6e4e390-2278-4a1c-8886-13d67507c818",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import boto3\n",
    "import numpy as np  \n",
    "import pandas as pd  \n",
    "import sagemaker\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c357f9a-0df7-4358-a231-62aaaeec605f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored variables and their in-db values:\n",
      "abalone_dataset_file_name                -> 'abalone.csv'\n",
      "abalone_dataset_local_url                -> '../dataset/abalone.csv'\n",
      "auto_ml_job_name                         -> 'automl-asinproc-24-14-33-56'\n",
      "bucket_name                              -> 'sagemaker-us-east-1-906545278380'\n",
      "bucket_prefix                            -> 'from-idea-to-prod/xgboost'\n",
      "customers_count                          -> 10000\n",
      "customers_feature_group_name             -> 'fscw-customers-07-20-17-46'\n",
      "data_bucket                              -> 'sagemaker-us-east-1-906545278380'\n",
      "data_uploaded                            -> True\n",
      "domain_id                                -> 'd-r8pbvl3oamh6'\n",
      "dw_flow_file_url                         -> 's3://sagemaker-us-east-1-906545278380/feature-sto\n",
      "dw_output_name                           -> '928854ec-259e-4130-8e0f-b65221b27d6e.default'\n",
      "endpoint_name                            -> 'reorder-classifier-2022-07-20-19-45-09-338'\n",
      "execution_role                           -> 'arn:aws:iam::906545278380:role/service-role/Amazo\n",
      "feature_group_name                       -> 'FG-abalone-06-19-27-51-42ea2f48'\n",
      "freq                                     -> '2H'\n",
      "initialized                              -> True\n",
      "orders_count                             -> 100000\n",
      "orders_feature_group_name                -> 'fscw-orders-07-20-17-46'\n",
      "products_count                           -> 17001\n",
      "products_feature_group_name              -> 'fscw-products-07-20-17-46'\n",
      "project_prefix                           -> 'loan-defaults'\n",
      "query_string                             -> 'SELECT * FROM \"fscw-customers-07-20-17-46-1658339\n",
      "region                                   -> 'us-east-1'\n",
      "s3_data_output_prefix                    -> 's3://sagemaker-us-east-1-906545278380/loan-defaul\n",
      "s3_data_prefix                           -> 's3://sagemaker-us-east-1-906545278380/loan-defaul\n",
      "s3_flow_prefix                           -> 's3://sagemaker-us-east-1-906545278380/loan-defaul\n",
      "s3_fs_query_output_prefix                -> 'sagemaker-us-east-1-906545278380/feature-store-in\n",
      "s3_input_data_prefix                     -> 'sagemaker-us-east-1-906545278380/feature-store-in\n",
      "s3_path                                  -> 's3://sagemaker-us-east-1-906545278380/loan-defaul\n",
      "s3_path_data                             -> 's3://sagemaker-us-east-1-906545278380/loan-defaul\n",
      "s3_test                                  -> 's3://sagemaker-us-east-1-906545278380/loan-defaul\n",
      "s3_to_fs_pipeline_name                   -> 's3-fs-ingest-pipeline-p-iwfgodxukuoo'\n",
      "sm_role                                  -> 'arn:aws:iam::906545278380:role/service-role/Amazo\n",
      "target_col                               -> 'y'\n",
      "test_data_s3_path                        -> 's3://sagemaker-us-east-1-906545278380/asin/test/t\n",
      "training_jobName                         -> 'reorder-classifier-2022-07-20-19-38-33-550'\n",
      "tuning_job_name                          -> 'mlu-dl1-xgb-tuning-220125-1108'\n",
      "xgb_train_job_name                       -> 'loan-defaults-2022-04-28-11-22-01-124'\n"
     ]
    }
   ],
   "source": [
    "%store -r \n",
    "\n",
    "%store\n",
    "\n",
    "try:\n",
    "    initialized\n",
    "except NameError:\n",
    "    print(\"+++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    print(\"[ERROR] YOU HAVE TO RUN 00-start-here notebook   \")\n",
    "    print(\"+++++++++++++++++++++++++++++++++++++++++++++++++\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b39c88c-6aed-47b4-8048-a27f35444e10",
   "metadata": {},
   "source": [
    "## Process data\n",
    "We use SageMaker processing by simply providing a Python data preprocessing script.\n",
    "We need to upload the input data to S3 and specify an S3 location for output data. SageMaker Processing automatically loads the input data from S3 and uploads transformed data back to S3 when the job is complete.\n",
    "\n",
    "![](img/sagemaker-processing.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b4f1fe-ef68-4151-8d7d-28269e39b68a",
   "metadata": {},
   "source": [
    "Upload the input dataset to an Amazon S3 bucket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5214e551-4800-47c2-9eae-337f4fc5ed7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_session = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01ba50c3-8428-4756-9a2c-8b6f8d19a52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_s3_url = sm_session.upload_data(\n",
    "    path=\"data/bank-additional/bank-additional-full.csv\",\n",
    "    bucket=bucket_name,\n",
    "    key_prefix=f\"{bucket_prefix}/input\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "118099a1-e789-435e-a309-4dd9043f219d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-21 08:54:54    5834924 from-idea-to-prod/xgboost/input/bank-additional-full.csv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls {bucket_name}/{bucket_prefix} --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a547ea17-c14a-41b4-a0d8-26164cf24615",
   "metadata": {},
   "source": [
    "We create a Python script by moving the data processing code from the step 1 to a .py file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25f6f89d-c9fa-4432-bf3e-5cc21aeb2e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting preprocessing.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile preprocessing.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "def _parse_args():\n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "    # Data, model, and output directories\n",
    "    # model_dir is always passed in from SageMaker. By default this is a S3 path under the default bucket.\n",
    "    parser.add_argument('--filepath', type=str, default='/opt/ml/processing/input/')\n",
    "    parser.add_argument('--filename', type=str, default='bank-additional-full.csv')\n",
    "    parser.add_argument('--outputpath', type=str, default='/opt/ml/processing/output/')\n",
    "    \n",
    "    return parser.parse_known_args()\n",
    "\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    # Process arguments\n",
    "    args, _ = _parse_args()\n",
    "    \n",
    "    target_col = \"y\"\n",
    "    \n",
    "    # Load data\n",
    "    df_data = pd.read_csv(os.path.join(args.filepath, args.filename), sep=\";\")\n",
    "\n",
    "    # Indicator variable to capture when pdays takes a value of 999\n",
    "    df_data[\"no_previous_contact\"] = np.where(df_data[\"pdays\"] == 999, 1, 0)\n",
    "\n",
    "    # Indicator for individuals not actively employed\n",
    "    df_data[\"not_working\"] = np.where(\n",
    "        np.in1d(df_data[\"job\"], [\"student\", \"retired\", \"unemployed\"]), 1, 0\n",
    "    )\n",
    "\n",
    "    # remove unnecessary data\n",
    "    df_model_data = df_data.drop(\n",
    "        [\"duration\", \"emp.var.rate\", \"cons.price.idx\", \"cons.conf.idx\", \"euribor3m\", \"nr.employed\"],\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    df_model_data = pd.get_dummies(df_model_data)  # Convert categorical variables to sets of indicators\n",
    "\n",
    "    # Replace \"y_no\" and \"y_yes\" with a single label column, and bring it to the front:\n",
    "    df_model_data = pd.concat(\n",
    "        [\n",
    "            df_model_data[\"y_yes\"].rename(target_col),\n",
    "            df_model_data.drop([\"y_no\", \"y_yes\"], axis=1),\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # Shuffle and splitting dataset\n",
    "    train_data, validation_data, test_data = np.split(\n",
    "        df_model_data.sample(frac=1, random_state=1729),\n",
    "        [int(0.7 * len(df_model_data)), int(0.9 * len(df_model_data))],\n",
    "    )\n",
    "\n",
    "    print(f\"Data split > train:{train_data.shape} | validation:{validation_data.shape} | test:{test_data.shape}\")\n",
    "    \n",
    "    # Save datasets locally\n",
    "    train_data.to_csv(os.path.join(args.outputpath, 'train/train.csv'), index=False, header=False)\n",
    "    validation_data.to_csv(os.path.join(args.outputpath, 'validation/validation.csv'), index=False, header=False)\n",
    "    test_data[target_col].to_csv(os.path.join(args.outputpath, 'test/test_y.csv'), index=False, header=False)\n",
    "    test_data.drop([target_col], axis=1).to_csv(os.path.join(args.outputpath, 'test/test_x.csv'), index=False, header=False)\n",
    "    \n",
    "    print(\"## Processing complete. Exiting.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ee5a09-46fd-4d7a-9037-9b6247a1f21d",
   "metadata": {},
   "source": [
    "Set the Amazon S3 paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54fa1abd-c0ae-4e55-901c-7250c227ccbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_s3_url = f\"s3://{bucket_name}/{bucket_prefix}/train\"\n",
    "validation_s3_url = f\"s3://{bucket_name}/{bucket_prefix}/validation\"\n",
    "test_s3_url = f\"s3://{bucket_name}/{bucket_prefix}/test\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b925880-49f1-4571-9761-02c4a96dbd62",
   "metadata": {},
   "source": [
    "Instantiate a [`SKLearnProcessor`](https://sagemaker.readthedocs.io/en/stable/frameworks/sklearn/sagemaker.sklearn.html#scikit-learn-processor) object before starting the SageMaker processing job. You specify the instance type to use in the job, as well as how many instances for distributed processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec206f04-99cc-4a4f-b622-1bb8fdac1460",
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_processor = SKLearnProcessor(\n",
    "    framework_version=\"0.23-1\",\n",
    "    role=sm_role,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    instance_count=1, \n",
    "    base_job_name='from-idea-to-prod-processing'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedef440-c13a-4d23-90af-ef747aeef8bc",
   "metadata": {},
   "source": [
    "Start the SageMaker processing job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bab839f9-6194-4467-b9d9-b207c15eb729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  from-idea-to-prod-processing-2022-09-21-10-03-07-464\n",
      "Inputs:  [{'InputName': 'input-1', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-906545278380/from-idea-to-prod/xgboost/input/bank-additional-full.csv', 'LocalPath': '/opt/ml/processing/input', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'ShardedByS3Key', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-906545278380/from-idea-to-prod-processing-2022-09-21-10-03-07-464/input/code/preprocessing.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'train_data', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-906545278380/from-idea-to-prod/xgboost/train', 'LocalPath': '/opt/ml/processing/output/train', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'validation_data', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-906545278380/from-idea-to-prod/xgboost/validation', 'LocalPath': '/opt/ml/processing/output/validation', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'test_data', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-906545278380/from-idea-to-prod/xgboost/test', 'LocalPath': '/opt/ml/processing/output/test', 'S3UploadMode': 'EndOfJob'}}]\n",
      ".............................\u001b[34mData split > train:(28831, 60) | validation:(8238, 60) | test:(4119, 60)\u001b[0m\n",
      "\u001b[34m## Processing complete. Exiting.\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sklearn_processor.run(\n",
    "    code='preprocessing.py',\n",
    "    # arguments = ['arg1', 'arg2'],\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=input_s3_url, \n",
    "            destination=\"/opt/ml/processing/input\",\n",
    "            s3_input_mode=\"File\",\n",
    "            s3_data_distribution_type=\"ShardedByS3Key\"\n",
    "        )\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            output_name=\"train_data\", \n",
    "            source=\"/opt/ml/processing/output/train\",\n",
    "            destination=train_s3_url,\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            output_name=\"validation_data\", \n",
    "            source=\"/opt/ml/processing/output/validation\", \n",
    "            destination=validation_s3_url\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            output_name=\"test_data\", \n",
    "            source=\"/opt/ml/processing/output/test\", \n",
    "            destination=test_s3_url\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ad2ceb4b-ece3-40c6-8674-ce7b8db70a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-21 08:54:54    5834924 from-idea-to-prod/xgboost/input/bank-additional-full.csv\n",
      "2022-09-21 12:34:58      14580 from-idea-to-prod/xgboost/output/from-idea-to-prod-training-2022-09-21-12-32-02-357/output/model.tar.gz\n",
      "2022-09-21 12:35:00          0 from-idea-to-prod/xgboost/output/from-idea-to-prod-training-2022-09-21-12-32-02-357/profiler-output/framework/training_job_end.ts\n",
      "2022-09-21 12:34:56      68641 from-idea-to-prod/xgboost/output/from-idea-to-prod-training-2022-09-21-12-32-02-357/profiler-output/system/incremental/2022092112/1663763580.algo-1.json\n",
      "2022-09-21 12:34:56     223781 from-idea-to-prod/xgboost/output/from-idea-to-prod-training-2022-09-21-12-32-02-357/profiler-output/system/incremental/2022092112/1663763640.algo-1.json\n",
      "2022-09-21 12:35:00          0 from-idea-to-prod/xgboost/output/from-idea-to-prod-training-2022-09-21-12-32-02-357/profiler-output/system/training_job_end.ts\n",
      "2022-09-21 12:37:19     329708 from-idea-to-prod/xgboost/output/from-idea-to-prod-training-2022-09-21-12-32-02-357/rule-output/ProfilerReport-1663763522/profiler-output/profiler-report.html\n",
      "2022-09-21 12:37:19     171075 from-idea-to-prod/xgboost/output/from-idea-to-prod-training-2022-09-21-12-32-02-357/rule-output/ProfilerReport-1663763522/profiler-output/profiler-report.ipynb\n",
      "2022-09-21 12:37:16        190 from-idea-to-prod/xgboost/output/from-idea-to-prod-training-2022-09-21-12-32-02-357/rule-output/ProfilerReport-1663763522/profiler-output/profiler-reports/BatchSize.json\n",
      "2022-09-21 12:37:16        198 from-idea-to-prod/xgboost/output/from-idea-to-prod-training-2022-09-21-12-32-02-357/rule-output/ProfilerReport-1663763522/profiler-output/profiler-reports/CPUBottleneck.json\n",
      "2022-09-21 12:37:16        126 from-idea-to-prod/xgboost/output/from-idea-to-prod-training-2022-09-21-12-32-02-357/rule-output/ProfilerReport-1663763522/profiler-output/profiler-reports/Dataloader.json\n",
      "2022-09-21 12:37:16        127 from-idea-to-prod/xgboost/output/from-idea-to-prod-training-2022-09-21-12-32-02-357/rule-output/ProfilerReport-1663763522/profiler-output/profiler-reports/GPUMemoryIncrease.json\n",
      "2022-09-21 12:37:16        197 from-idea-to-prod/xgboost/output/from-idea-to-prod-training-2022-09-21-12-32-02-357/rule-output/ProfilerReport-1663763522/profiler-output/profiler-reports/IOBottleneck.json\n",
      "2022-09-21 12:37:16        119 from-idea-to-prod/xgboost/output/from-idea-to-prod-training-2022-09-21-12-32-02-357/rule-output/ProfilerReport-1663763522/profiler-output/profiler-reports/LoadBalancing.json\n",
      "2022-09-21 12:37:16        151 from-idea-to-prod/xgboost/output/from-idea-to-prod-training-2022-09-21-12-32-02-357/rule-output/ProfilerReport-1663763522/profiler-output/profiler-reports/LowGPUUtilization.json\n",
      "2022-09-21 12:37:16        179 from-idea-to-prod/xgboost/output/from-idea-to-prod-training-2022-09-21-12-32-02-357/rule-output/ProfilerReport-1663763522/profiler-output/profiler-reports/MaxInitializationTime.json\n",
      "2022-09-21 12:37:16        133 from-idea-to-prod/xgboost/output/from-idea-to-prod-training-2022-09-21-12-32-02-357/rule-output/ProfilerReport-1663763522/profiler-output/profiler-reports/OverallFrameworkMetrics.json\n",
      "2022-09-21 12:37:16        465 from-idea-to-prod/xgboost/output/from-idea-to-prod-training-2022-09-21-12-32-02-357/rule-output/ProfilerReport-1663763522/profiler-output/profiler-reports/OverallSystemUsage.json\n",
      "2022-09-21 12:37:16        156 from-idea-to-prod/xgboost/output/from-idea-to-prod-training-2022-09-21-12-32-02-357/rule-output/ProfilerReport-1663763522/profiler-output/profiler-reports/StepOutlier.json\n",
      "2022-09-21 10:07:56     498254 from-idea-to-prod/xgboost/test/test_x.csv\n",
      "2022-09-21 10:07:56       8238 from-idea-to-prod/xgboost/test/test_y.csv\n",
      "2022-09-21 10:07:56    3544984 from-idea-to-prod/xgboost/train/train.csv\n",
      "2022-09-21 10:07:56    1012968 from-idea-to-prod/xgboost/validation/validation.csv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls {bucket_name}/{bucket_prefix} --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d25d03a-e988-4a73-acdd-874718d03a74",
   "metadata": {},
   "source": [
    "## Model training\n",
    "We follow the same approach and now run the model training as a SageMaker training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dfbeec6d-419d-4d88-a3f6-194440dd0124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "811284229777.dkr.ecr.us-east-1.amazonaws.com/xgboost:latest\n"
     ]
    }
   ],
   "source": [
    "# get training container uri\n",
    "training_image = sagemaker.image_uris.retrieve(\"xgboost\", region=region, version=\"latest\")\n",
    "\n",
    "print(training_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64034359-5102-4678-af52-aba7f21a4212",
   "metadata": {},
   "source": [
    "Define the data input channels for the training job. We use _train_ and _validation_ channels via the SageMaker SDK [`TrainingInput`](https://sagemaker.readthedocs.io/en/stable/api/utility/inputs.html#sagemaker.inputs.TrainingInput) class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "82550351-737f-4a55-9578-0ae58ca1c156",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_input_train = sagemaker.inputs.TrainingInput(train_s3_url, content_type='csv')\n",
    "s3_input_validation = sagemaker.inputs.TrainingInput(validation_s3_url, content_type='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "86c9a303-928a-4053-9002-cd618cffa6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_count = 1\n",
    "instance_type = \"ml.m5.xlarge\"\n",
    "\n",
    "output_s3_url = f\"s3://{bucket_name}/{bucket_prefix}/output\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54807668-6a2d-44ac-9007-d945ec19198a",
   "metadata": {},
   "source": [
    "Instantiate an Estimator object and set algorithm's hyperparameters. Refer to [XGBoost hyperparameters](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost_hyperparameters.html) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "db1a89cc-c841-4e5d-99b3-d4fe5b6435cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate an XGBoost estimator object\n",
    "estimator = sagemaker.estimator.Estimator(\n",
    "    image_uri=training_image,  # XGBoost algorithm container\n",
    "    instance_type=instance_type,  # type of training instance\n",
    "    instance_count=instance_count,  # number of instances to be used\n",
    "    role=sm_role,  # IAM execution role to be used\n",
    "    max_run=20 * 60,  # Maximum allowed active runtime\n",
    "    # use_spot_instances=True,  # Use spot instances to reduce cost\n",
    "    # max_wait=30 * 60,  # Maximum clock time (including spot delays)\n",
    "    output_path=output_s3_url, # S3 location for saving the training result\n",
    "    sagemaker_session=sm_session, # Session object which manages interactions with SageMaker API and AWS services\n",
    "    base_job_name=\"from-idea-to-prod-training\", # Prefix for training job name\n",
    ")\n",
    "\n",
    "# define its hyperparameters\n",
    "estimator.set_hyperparameters(\n",
    "    num_round=150, # the number of rounds to run the training\n",
    "    max_depth=5, # maximum depth of a tree\n",
    "    eta=0.5, # step size shrinkage used in updates to prevent overfitting\n",
    "    alpha=2.5, # L1 regularization term on weights\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"auc\", # evaluation metrics for validation data\n",
    "    subsample=0.8, # subsample ratio of the training instance\n",
    "    colsample_bytree=0.8, # subsample ratio of columns when constructing each tree\n",
    "    min_child_weight=3, # minimum sum of instance weight (hessian) needed in a child\n",
    "    early_stopping_rounds=10, # the model trains until the validation score stops improving\n",
    "    verbosity=1, # verbosity of printing messages\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3022218-4f87-4e59-8f58-9bab2a44bb96",
   "metadata": {},
   "source": [
    "Run the training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "287da7a9-c0ca-479e-8677-24176d91f95f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-21 12:32:02 Starting - Starting the training job...\n",
      "2022-09-21 12:32:19 Starting - Preparing the instances for trainingProfilerReport-1663763522: InProgress\n",
      "......\n",
      "2022-09-21 12:33:31 Downloading - Downloading input data......\n",
      "2022-09-21 12:34:14 Training - Downloading the training image..\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[2022-09-21:12:34:44:INFO] Running standalone xgboost training.\u001b[0m\n",
      "\u001b[34m[2022-09-21:12:34:44:INFO] File size need to be processed in the node: 4.35mb. Available memory size in the node: 8461.7mb\u001b[0m\n",
      "\u001b[34m[2022-09-21:12:34:44:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[12:34:44] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[12:34:44] 28831x59 matrix with 1701029 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[2022-09-21:12:34:44:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[12:34:44] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[12:34:44] 8238x59 matrix with 486042 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[12:34:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[0]#011train-auc:0.712931#011validation-auc:0.708107\u001b[0m\n",
      "\u001b[34mMultiple eval metrics have been passed: 'validation-auc' will be used for early stopping.\u001b[0m\n",
      "\u001b[34mWill train until validation-auc hasn't improved in 10 rounds.\u001b[0m\n",
      "\u001b[34m[12:34:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[1]#011train-auc:0.741804#011validation-auc:0.737522\u001b[0m\n",
      "\u001b[34m[12:34:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2]#011train-auc:0.75469#011validation-auc:0.749496\u001b[0m\n",
      "\u001b[34m[12:34:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[3]#011train-auc:0.770449#011validation-auc:0.762909\u001b[0m\n",
      "\u001b[34m[12:34:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[4]#011train-auc:0.772229#011validation-auc:0.76355\u001b[0m\n",
      "\u001b[34m[12:34:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[5]#011train-auc:0.776616#011validation-auc:0.767533\u001b[0m\n",
      "\u001b[34m[12:34:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[6]#011train-auc:0.777759#011validation-auc:0.767718\u001b[0m\n",
      "\u001b[34m[12:34:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[7]#011train-auc:0.780774#011validation-auc:0.770462\u001b[0m\n",
      "\u001b[34m[12:34:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[8]#011train-auc:0.783291#011validation-auc:0.77311\u001b[0m\n",
      "\u001b[34m[12:34:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[9]#011train-auc:0.785655#011validation-auc:0.771256\u001b[0m\n",
      "\u001b[34m[12:34:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[10]#011train-auc:0.787208#011validation-auc:0.771676\u001b[0m\n",
      "\u001b[34m[12:34:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[11]#011train-auc:0.791364#011validation-auc:0.77233\u001b[0m\n",
      "\u001b[34m[12:34:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[12]#011train-auc:0.794347#011validation-auc:0.768201\u001b[0m\n",
      "\u001b[34m[12:34:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[13]#011train-auc:0.795351#011validation-auc:0.768112\u001b[0m\n",
      "\u001b[34m[12:34:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[14]#011train-auc:0.796819#011validation-auc:0.76838\u001b[0m\n",
      "\u001b[34m[12:34:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[15]#011train-auc:0.797961#011validation-auc:0.76864\u001b[0m\n",
      "\u001b[34m[12:34:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[16]#011train-auc:0.799357#011validation-auc:0.767444\u001b[0m\n",
      "\u001b[34m[12:34:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[17]#011train-auc:0.800957#011validation-auc:0.766939\u001b[0m\n",
      "\u001b[34m[12:34:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[18]#011train-auc:0.802572#011validation-auc:0.76729\u001b[0m\n",
      "\u001b[34mStopping. Best iteration:\u001b[0m\n",
      "\u001b[34m[8]#011train-auc:0.783291#011validation-auc:0.77311\u001b[0m\n",
      "\n",
      "2022-09-21 12:35:03 Uploading - Uploading generated training model\n",
      "2022-09-21 12:35:03 Completed - Training job completed\n",
      "Training seconds: 92\n",
      "Billable seconds: 92\n"
     ]
    }
   ],
   "source": [
    "estimator.fit({'train': s3_input_train, 'validation': s3_input_validation}) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b9af81-09c1-45b1-b59b-489a0d14fa76",
   "metadata": {},
   "source": [
    "Output model performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a69d7a0c-8cbe-4fd1-af44-9677107b5229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-auc:0.78, Validate-auc:0.77\n"
     ]
    }
   ],
   "source": [
    "metrics = boto3.client(\"sagemaker\", region_name=region).describe_training_job(\n",
    "    TrainingJobName=estimator._current_job_name\n",
    "    )[\"FinalMetricDataList\"]\n",
    "\n",
    "train_auc = float([m['Value'] for m in metrics if m['MetricName'] == 'train:auc'][0])\n",
    "validate_auc = float([m['Value'] for m in metrics if m['MetricName'] == 'validation:auc'][0])\n",
    "\n",
    "print(f\"Train-auc:{train_auc:.2f}, Validate-auc:{validate_auc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa43bd9-7cab-48da-b128-635b90c49971",
   "metadata": {},
   "source": [
    "## Validate model\n",
    "Now we have a model saved in the specified location on Amazon S3. We deploy the model as a real-time endpoint, which is just one function call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "feb0d417-99e8-480d-baa4-7ab18d9b5427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------!"
     ]
    }
   ],
   "source": [
    "# Real-time endpoint:\n",
    "predictor = estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    # wait=False,  # Remember, predictor.predict() won't work until deployment finishes!\n",
    "    # We will also turn on data capture here, in case you want to experiment with monitoring later:\n",
    "    data_capture_config=sagemaker.model_monitor.DataCaptureConfig(\n",
    "        enable_capture=True,\n",
    "        sampling_percentage=100,\n",
    "        destination_s3_uri=f\"s3://{bucket_name}/{bucket_prefix}/data-capture\",\n",
    "    ),\n",
    "    serializer=sagemaker.serializers.CSVSerializer(),\n",
    "    deserializer=sagemaker.deserializers.CSVDeserializer(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "afe4d085-0c98-49db-bc61-b14e93e9f21e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-east-1-906545278380/from-idea-to-prod/xgboost/test/test_x.csv to tmp/test_x.csv\n",
      "download: s3://sagemaker-us-east-1-906545278380/from-idea-to-prod/xgboost/test/test_y.csv to tmp/test_y.csv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp $test_s3_url/test_x.csv tmp/test_x.csv\n",
    "!aws s3 cp $test_s3_url/test_y.csv tmp/test_y.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cbfeb79b-014e-4784-a7bd-52f88b9957db",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = pd.read_csv(\"tmp/test_x.csv\", names=[f'{i}' for i in range(59)])\n",
    "test_y = pd.read_csv(\"tmp/test_y.csv\", names=['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b5d420ff-2e3e-466a-b8e4-91a2f407f26d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05137555, 0.09782112, 0.22581661, ..., 0.04346842, 0.04000453,\n",
       "       0.03656681])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = np.array(predictor.predict(test_x.values), dtype=float).squeeze()\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ce21400a-6cbd-4817-869d-89e289fa165b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_pred</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.051376</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.097821</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.225817</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.269298</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.040005</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_pred   0  1    2  3  4  5  6  7  8  ...  49  50  51  52  53  54  55  \\\n",
       "0  0.051376  25  1  999  0  1  0  0  0  0  ...   0   0   0   1   0   0   0   \n",
       "1  0.097821  28  3  999  0  1  0  0  0  0  ...   0   0   0   0   0   1   0   \n",
       "2  0.225817  38  1  999  0  1  0  1  0  0  ...   0   0   0   1   0   0   0   \n",
       "3  0.269298  32  1  999  1  1  0  1  0  0  ...   0   0   0   1   0   0   0   \n",
       "4  0.040005  40  1  999  0  1  0  0  0  0  ...   0   0   0   0   0   1   0   \n",
       "\n",
       "   56  57  58  \n",
       "0   0   1   0  \n",
       "1   0   1   0  \n",
       "2   0   1   0  \n",
       "3   1   0   0  \n",
       "4   0   1   0  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results = pd.concat(\n",
    "    [\n",
    "        pd.Series(predictions, name=\"y_pred\", index=test_x.index),\n",
    "        test_x,\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "test_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "91b8ef37-c50d-465d-bf54-2b104ace6fe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predictions</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actuals</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3589</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>387</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predictions   0.0  1.0\n",
       "actuals               \n",
       "0            3589   47\n",
       "1             387   96"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(\n",
    "    index=test_y['y'].values,\n",
    "    columns=np.round(predictions), \n",
    "    rownames=['actuals'], \n",
    "    colnames=['predictions']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f994e5e0-b83f-4c39-b9fe-9e0c74b2b4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test-auc: 0.77\n"
     ]
    }
   ],
   "source": [
    "test_auc = roc_auc_score(test_y, test_results[\"y_pred\"])\n",
    "print(f\"Test-auc: {test_auc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8a7389-9af4-4a0b-8ea7-376db0c2ed02",
   "metadata": {},
   "source": [
    "## Optional: Hyperparameter Optimization (HPO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a31feb51-0ca9-4517-8c1a-02415970a46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required HPO objects\n",
    "from sagemaker.tuner import (\n",
    "    CategoricalParameter,\n",
    "    ContinuousParameter,\n",
    "    HyperparameterTuner,\n",
    "    IntegerParameter,\n",
    ")\n",
    "\n",
    "# set up hyperparameter ranges\n",
    "hp_ranges = {\n",
    "    \"min_child_weight\": ContinuousParameter(1, 10),\n",
    "    \"max_depth\": IntegerParameter(1, 10),\n",
    "    \"alpha\": ContinuousParameter(0, 5),\n",
    "    \"eta\": ContinuousParameter(0, 1),\n",
    "}\n",
    "\n",
    "# set up the objective metric\n",
    "objective = \"validation:auc\"\n",
    "\n",
    "# instantiate a HPO object\n",
    "tuner = HyperparameterTuner(\n",
    "    estimator=estimator,  # the SageMaker estimator object\n",
    "    hyperparameter_ranges=hp_ranges,  # the range of hyperparameters\n",
    "    max_jobs=20,  # total number of HPO jobs\n",
    "    max_parallel_jobs=2,  # how many HPO jobs can run in parallel\n",
    "    strategy=\"Bayesian\",  # the internal optimization strategy of HPO\n",
    "    objective_metric_name=objective,  # the objective metric to be used for HPO\n",
    "    objective_type=\"Maximize\",  # maximize or minimize the objective metric\n",
    "    base_tuning_job_name=\"from-idea-to-prod-hpo\",\n",
    "    early_stopping_type=\"Auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "612a815f-c9f9-4e8e-9afb-ffd3b98a0f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...............................................................................................................................................!\n"
     ]
    }
   ],
   "source": [
    "tuner.fit({\"train\": s3_input_train, \"validation\": s3_input_validation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d60e7673-1d4f-4632-b5cc-c0745cb83260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HPO job status: Completed\n"
     ]
    }
   ],
   "source": [
    "print(f\"HPO job status: {boto3.client('sagemaker').describe_hyper_parameter_tuning_job(HyperParameterTuningJobName=tuner.latest_tuning_job.job_name)['HyperParameterTuningJobStatus']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "fc88733a-0711-4248-9acd-c7d78e4f1830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2022-09-21 14:14:45 Starting - Preparing the instances for training\n",
      "2022-09-21 14:14:45 Downloading - Downloading input data\n",
      "2022-09-21 14:14:45 Training - Training image download completed. Training in progress.\n",
      "2022-09-21 14:14:45 Uploading - Uploading generated training model\n",
      "2022-09-21 14:14:45 Completed - Resource reused by training job: from-idea-to-prod-hp-220921-1410-004-7b86e51c\n",
      "-----!"
     ]
    }
   ],
   "source": [
    "hpo_predictor = tuner.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    serializer=sagemaker.serializers.CSVSerializer(),\n",
    "    deserializer=sagemaker.deserializers.CSVDeserializer(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "3337f1c6-f211-4054-907f-ef0ee17683f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.06523537 0.09084037 0.17831463 ... 0.03452097 0.03494474 0.03519909]\n"
     ]
    }
   ],
   "source": [
    "hpo_predictions = np.array(hpo_predictor.predict(test_x.values), dtype=float).squeeze()\n",
    "print(hpo_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "d77cc440-3828-4677-b19b-ede1edcb3903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predictions</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actuals</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3588</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>387</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predictions   0.0  1.0\n",
       "actuals               \n",
       "0            3588   48\n",
       "1             387   96"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(\n",
    "    index=test_y['y'].values,\n",
    "    columns=np.round(hpo_predictions), \n",
    "    rownames=['actuals'], \n",
    "    colnames=['predictions']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5493780-c392-4432-a34b-75f27ce984a5",
   "metadata": {},
   "source": [
    "## Clean-up\n",
    "To avoid charges, remove the hosted endpoint you created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de13080-5527-4de4-aacb-3eb50af0f92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint(delete_endpoint_config=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040e95d7-b906-4a7c-90cb-4d73cefbf617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run if you created a tuned predictor after HPO\n",
    "hpo_predictor.delete_endpoint(delete_endpoint_config=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f720e0-e8d5-4cb5-93a6-6a4f2dafd523",
   "metadata": {},
   "source": [
    "## Continue with the step 3\n",
    "open the step 3 [notebook](02-sagemaker-pipeline.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba1fc9d-7a52-4d2f-b51e-0f9422119389",
   "metadata": {},
   "source": [
    "## Additional resources\n",
    "- [Amazon SageMaker Immersion Day](https://catalog.us-east-1.prod.workshops.aws/workshops/63069e26-921c-4ce1-9cc7-dd882ff62575/en-US)\n",
    "- [Amazon SageMaker 101 Workshop](https://catalog.us-east-1.prod.workshops.aws/workshops/0c6b8a23-b837-4e0f-b2e2-4a3ffd7d645b/en-US)\n",
    "- [Amazon SageMaker 101 Workshop code repository](https://github.com/aws-samples/sagemaker-101-workshop)\n",
    "- [Amazon SageMaker with XGBoost and Hyperparameter Tuning for Direct Marketing predictions](https://github.com/aws-samples/sagemaker-101-workshop/blob/main/builtin_algorithm_hpo_tabular/SageMaker%20XGBoost%20HPO.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7b222f-ee83-4c87-9019-cebcc7e56627",
   "metadata": {},
   "source": [
    "# Shutdown kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0b1f02-44b8-4749-a5e2-ce415fff7f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "\n",
    "<p><b>Shutting down your kernel for this notebook to release resources.</b></p>\n",
    "<button class=\"sm-command-button\" data-commandlinker-command=\"kernelmenu:shutdown\" style=\"display:none;\">Shutdown Kernel</button>\n",
    "        \n",
    "<script>\n",
    "try {\n",
    "    els = document.getElementsByClassName(\"sm-command-button\");\n",
    "    els[0].click();\n",
    "}\n",
    "catch(err) {\n",
    "    // NoOp\n",
    "}    \n",
    "</script>"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
