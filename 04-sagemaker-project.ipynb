{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6eb825bb-e3c2-4838-b73c-528e1fc25735",
   "metadata": {},
   "source": [
    "# Step 4: Add a model building CI/CD pipeline\n",
    "\n",
    "In this step we create an automated CI/CD pipeline for model building using [Amazon SageMaker Projects](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-projects.html). \n",
    "\n",
    "![](img/six-steps-4.png)\n",
    "\n",
    "We use a [SageMaker-provided MLOps project template for model building and training](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-projects-templates-sm.html#sagemaker-projects-templates-code-commit) to provision a ready-to use CI/CD workflow automation with [AWS CodePipeline](https://aws.amazon.com/codepipeline/) and an [AWS CodeCommit](https://aws.amazon.com/codecommit/) code repository.\n",
    "\n",
    "SageMaker project templates offer you the following choice of code repositories, workflow automation tools, and pipeline stages:\n",
    "- **Code repository**: AWS CodeCommit or third-party Git repositories such as GitHub and Bitbucket\n",
    "- **CI/CD workflow automation**: AWS CodePipeline or Jenkins\n",
    "- **Pipeline stages**: Model building and training, model deployment, or both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42102a0b-a706-43b3-9f23-59f7084123f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c0dd762-ba2a-4141-b937-80cfccf98faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored variables and their in-db values:\n",
      "abalone_dataset_file_name                -> 'abalone.csv'\n",
      "abalone_dataset_local_url                -> '../dataset/abalone.csv'\n",
      "auto_ml_job_name                         -> 'automl-asinproc-24-14-33-56'\n",
      "bucket_name                              -> 'sagemaker-us-east-1-906545278380'\n",
      "bucket_prefix                            -> 'from-idea-to-prod/xgboost'\n",
      "customers_count                          -> 10000\n",
      "customers_feature_group_name             -> 'fscw-customers-07-20-17-46'\n",
      "data_bucket                              -> 'sagemaker-us-east-1-906545278380'\n",
      "data_uploaded                            -> True\n",
      "domain_id                                -> 'd-r8pbvl3oamh6'\n",
      "dw_flow_file_url                         -> 's3://sagemaker-us-east-1-906545278380/feature-sto\n",
      "dw_output_name                           -> '928854ec-259e-4130-8e0f-b65221b27d6e.default'\n",
      "endpoint_name                            -> 'reorder-classifier-2022-07-20-19-45-09-338'\n",
      "execution_role                           -> 'arn:aws:iam::906545278380:role/service-role/Amazo\n",
      "feature_group_name                       -> 'FG-abalone-06-19-27-51-42ea2f48'\n",
      "freq                                     -> '2H'\n",
      "initialized                              -> True\n",
      "input_s3_url                             -> 's3://sagemaker-us-east-1-906545278380/from-idea-t\n",
      "orders_count                             -> 100000\n",
      "orders_feature_group_name                -> 'fscw-orders-07-20-17-46'\n",
      "output_s3_url                            -> 's3://sagemaker-us-east-1-906545278380/from-idea-t\n",
      "products_count                           -> 17001\n",
      "products_feature_group_name              -> 'fscw-products-07-20-17-46'\n",
      "project_prefix                           -> 'loan-defaults'\n",
      "query_string                             -> 'SELECT * FROM \"fscw-customers-07-20-17-46-1658339\n",
      "region                                   -> 'us-east-1'\n",
      "s3_data_output_prefix                    -> 's3://sagemaker-us-east-1-906545278380/loan-defaul\n",
      "s3_data_prefix                           -> 's3://sagemaker-us-east-1-906545278380/loan-defaul\n",
      "s3_flow_prefix                           -> 's3://sagemaker-us-east-1-906545278380/loan-defaul\n",
      "s3_fs_query_output_prefix                -> 'sagemaker-us-east-1-906545278380/feature-store-in\n",
      "s3_input_data_prefix                     -> 'sagemaker-us-east-1-906545278380/feature-store-in\n",
      "s3_path                                  -> 's3://sagemaker-us-east-1-906545278380/loan-defaul\n",
      "s3_path_data                             -> 's3://sagemaker-us-east-1-906545278380/loan-defaul\n",
      "s3_test                                  -> 's3://sagemaker-us-east-1-906545278380/loan-defaul\n",
      "s3_to_fs_pipeline_name                   -> 's3-fs-ingest-pipeline-p-iwfgodxukuoo'\n",
      "sm_role                                  -> 'arn:aws:iam::906545278380:role/service-role/Amazo\n",
      "target_col                               -> 'y'\n",
      "test_data_s3_path                        -> 's3://sagemaker-us-east-1-906545278380/asin/test/t\n",
      "training_jobName                         -> 'reorder-classifier-2022-07-20-19-38-33-550'\n",
      "tuning_job_name                          -> 'mlu-dl1-xgb-tuning-220125-1108'\n",
      "xgb_train_job_name                       -> 'loan-defaults-2022-04-28-11-22-01-124'\n"
     ]
    }
   ],
   "source": [
    "%store -r \n",
    "\n",
    "%store\n",
    "\n",
    "try:\n",
    "    initialized\n",
    "except NameError:\n",
    "    print(\"+++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    print(\"[ERROR] YOU HAVE TO RUN 00-start-here notebook   \")\n",
    "    print(\"+++++++++++++++++++++++++++++++++++++++++++++++++\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaeaa68c-a2aa-4da5-8577-42d7dff2067a",
   "metadata": {},
   "source": [
    "## Create an MLOps project\n",
    "‚≠ê You can create a project programmatically in this notebook (Option 1) or in Studio (Option 2). Option 1 is recommended as it requires no manual input. Option 2 is given to demonstrate [**Create Project** UX flow](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-projects-create.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7061c4-b0f5-48a9-999c-1b0b84c8a4b9",
   "metadata": {},
   "source": [
    "###¬†Option 1: Create project programmatically\n",
    "We use `boto3` to create an MLOps project via a SageMaker API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7792b450-40ea-47f8-9449-528148ae43f5",
   "metadata": {},
   "source": [
    "### Option 2: Create a project in Studio\n",
    "<div class=\"alert alert-info\"> üí° <strong> Skip this section if you created a project programmatically </strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a0bcfd-94e3-4892-8199-6ca06593c0af",
   "metadata": {},
   "source": [
    "To create a project in Studio:\n",
    "\n",
    "1. In the Studio sidebar, choose the **SageMaker resources** icon.\n",
    "2. Select **Projects** from the dropdown list.\n",
    "3. Choose **Create project**.\n",
    "    - The **Create project** tab opens displaying a list of available templates.\n",
    "4. For **SageMaker project templates**, choose **SageMaker templates**. \n",
    "5. Choose **MLOps template for model building and training**\n",
    "6. Choose **Select project template**.\n",
    "\n",
    "![](img/create-mlops-project.png)\n",
    "\n",
    "The **Create project** tab changes to display **Project details**.\n",
    "\n",
    "![](img/project-details.png)\n",
    "\n",
    "Enter the following information:\n",
    "- For **Project details**, enter a name and description for your project. Note the name requirements.\n",
    "- Optionally, add tags, which are key-value pairs that you can use to track your projects.\n",
    "\n",
    "Choose **Create project** and wait for the project to appear in the Projects list."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f8a881-3e06-4497-8dce-e73dc6923ce4",
   "metadata": {},
   "source": [
    "### Resolve issues with project creation\n",
    "‚ùó If you see an error message similar to:\n",
    "```\n",
    "Your project couldn't be created\n",
    "Studio encountered an error when creating your project. Try recreating the project again.\n",
    "\n",
    "CodeBuild is not authorized to perform: sts:AssumeRole on arn:aws:iam::XXXX:role/service-role/AmazonSageMakerServiceCatalogProductsCodeBuildRole (Service: AWSCodeBuild; Status Code: 400; Error Code: InvalidInputException; Request ID: 4cf59a54-0c59-476a-a970-0ac656db4402; Proxy: null)\n",
    "```\n",
    "\n",
    "see steps 5-6 of [SageMaker Studio Permissions Required to Use Projects](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-projects-studio-updates.html). Make sure you have all required project roles listed in the **Apps** card under **Projects**. \n",
    "\n",
    "üí° If you don't have these roles, you must follow [Shut Down and Update SageMaker Studio and Studio Apps](https://docs.aws.amazon.com/sagemaker/latest/dg/studio-tasks-update.html) instructions to update the domain. You must shutdown both JupyterServer and KernelGateway apps. After you shutdown all apps, go to Amazon SageMaker **Control Panel**, choose **Configure app** on the **App** card. Click through all **Next** in configuration panes and choose **Submit**. This will update the domain and create all needed project roles automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976166a9-0769-4db8-924d-270b25d91acb",
   "metadata": {},
   "source": [
    "## Configure the MLOps project\n",
    "The project takes about 3-5 min to be created. The project runs a provided default model building pipeline automatically as soon as it has been created.\n",
    "The project templates deploys the following architecture in your environment:\n",
    "\n",
    "![](img/mlops-model-build-train.png)\n",
    "\n",
    "The main components are:\n",
    "1. The project template is made available through SageMaker Projects and AWS Service Catalog portfolio\n",
    "2. A CodePipeline pipeline with two stages - `Source` to download the source code from a CodeCommit repository and `Build` to create and execute a SageMaker pipeline\n",
    "3. A default SageMaker pipeline with model build, train, and register workflow\n",
    "4. A seed code repository in CodeCommit with a provided default version of the scaffolding code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edd547c-b9ec-4902-b798-2e4ac6cae2c1",
   "metadata": {},
   "source": [
    "This project contains all the required code and the insfrastructure to implement an automated CI/CD pipeline. \n",
    "To start using the project with your pipeline, you need to complete the following steps:\n",
    "1. Clone the provided project seed code to Studio environment\n",
    "2. Replace the pipeline creation sample code with your pipeline construction code, as implemented in the step 3 notebook\n",
    "3. Modify the `codebuild-buildspec.yml` file to reference the correct Python module name and to set project parameters\n",
    "\n",
    "Next sections guide you through these steps. For detailed instructions and a hands-on example, refer to the development guide [SageMaker MLOps Project Walkthrough](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-projects-walkthrough.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e398fd92-8e76-43a0-9b61-3bb5291d880f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1. Clone the project seed code to the Studio file system\n",
    "1. Choose **SageMaker resources** in the Studio sidebar and then select **Projects**\n",
    "2. Select the name of the project you created and double-click on it to open the project details tab\n",
    "3. In the project tab, choose **Repositories**, and in the **Local path** column for the repository choose **clone repo....**\n",
    "4. In the dialog box that appears choose **Clone Repository**\n",
    "\n",
    "![](img/clone-project-repo.png)\n",
    "\n",
    "When clone of the repository is complete, the local path appears in the **Local path** column. Choose the path to open the local folder that contains the repository code in Studio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2982e5ab-98d0-4c44-b1c5-32dffbc1a4e3",
   "metadata": {},
   "source": [
    "### 2. Replace pipeline construction code\n",
    "In Studio file browser navigate to the `pipelines` folder inside the project folder and rename the `abalone` folder to `fromideatoprod`.\n",
    "\n",
    "Copy the `preprocessing.py` file that we created in the step 2 from the `amazon-sagemaker-from-idea-to-production` folder to the `pipelines/fromideatoprod` folder in the project's code repository folder, which looks like `sagemaker-<project-name>-<project-id>-modelbuild`.\n",
    "\n",
    "Execute the following cell to write pipeline construction code to the file `pipeline.py`. We re-use the code from the step 3 notebook as the function `get_pipeline()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e15c1c4-e04e-45f1-8c48-6f87e46e6a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting pipeline.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile pipeline.py\n",
    "\n",
    "import os\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "import sagemaker.session\n",
    "\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.model_metrics import (\n",
    "    MetricsSource,\n",
    "    ModelMetrics,\n",
    ")\n",
    "from sagemaker.processing import (\n",
    "    ProcessingInput,\n",
    "    ProcessingOutput,\n",
    "    ScriptProcessor,\n",
    ")\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.workflow.conditions import ConditionLessThanOrEqualTo\n",
    "from sagemaker.workflow.condition_step import (\n",
    "    ConditionStep,\n",
    ")\n",
    "from sagemaker.workflow.functions import (\n",
    "    JsonGet,\n",
    ")\n",
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterInteger,\n",
    "    ParameterString,\n",
    ")\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "from sagemaker.workflow.steps import (\n",
    "    ProcessingStep,\n",
    "    TrainingStep,\n",
    ")\n",
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "from sagemaker.workflow.model_step import ModelStep\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "\n",
    "\n",
    "BASE_DIR = os.path.dirname(os.path.realpath(__file__))\n",
    "\n",
    "def get_sagemaker_client(region):\n",
    "     \"\"\"Gets the sagemaker client.\n",
    "\n",
    "        Args:\n",
    "            region: the aws region to start the session\n",
    "            default_bucket: the bucket to use for storing the artifacts\n",
    "\n",
    "        Returns:\n",
    "            `sagemaker.session.Session instance\n",
    "        \"\"\"\n",
    "     boto_session = boto3.Session(region_name=region)\n",
    "     sagemaker_client = boto_session.client(\"sagemaker\")\n",
    "     return sagemaker_client\n",
    "\n",
    "\n",
    "def get_session(region, default_bucket):\n",
    "    \"\"\"Gets the sagemaker session based on the region.\n",
    "\n",
    "    Args:\n",
    "        region: the aws region to start the session\n",
    "        default_bucket: the bucket to use for storing the artifacts\n",
    "\n",
    "    Returns:\n",
    "        `sagemaker.session.Session instance\n",
    "    \"\"\"\n",
    "\n",
    "    boto_session = boto3.Session(region_name=region)\n",
    "\n",
    "    sagemaker_client = boto_session.client(\"sagemaker\")\n",
    "    runtime_client = boto_session.client(\"sagemaker-runtime\")\n",
    "    return sagemaker.session.Session(\n",
    "        boto_session=boto_session,\n",
    "        sagemaker_client=sagemaker_client,\n",
    "        sagemaker_runtime_client=runtime_client,\n",
    "        default_bucket=default_bucket,\n",
    "    )\n",
    "\n",
    "def get_pipeline_session(region, default_bucket):\n",
    "    \"\"\"Gets the pipeline session based on the region.\n",
    "\n",
    "    Args:\n",
    "        region: the aws region to start the session\n",
    "        default_bucket: the bucket to use for storing the artifacts\n",
    "\n",
    "    Returns:\n",
    "        PipelineSession instance\n",
    "    \"\"\"\n",
    "\n",
    "    boto_session = boto3.Session(region_name=region)\n",
    "    sagemaker_client = boto_session.client(\"sagemaker\")\n",
    "\n",
    "    return PipelineSession(\n",
    "        boto_session=boto_session,\n",
    "        sagemaker_client=sagemaker_client,\n",
    "        default_bucket=default_bucket,\n",
    "    )\n",
    "\n",
    "def get_pipeline_custom_tags(new_tags, region, sagemaker_project_arn=None):\n",
    "    try:\n",
    "        sm_client = get_sagemaker_client(region)\n",
    "        response = sm_client.list_tags(\n",
    "            ResourceArn=sagemaker_project_arn)\n",
    "        project_tags = response[\"Tags\"]\n",
    "        for project_tag in project_tags:\n",
    "            new_tags.append(project_tag)\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting project tags: {e}\")\n",
    "    return new_tags\n",
    "\n",
    "\n",
    "def get_pipeline(\n",
    "    region,\n",
    "    sagemaker_project_arn=None,\n",
    "    role=None,\n",
    "    default_bucket=None,\n",
    "    input_data_url=None,\n",
    "    bucket_prefix=\"from-idea-to-prod/xgboost\",\n",
    "    model_package_group_name=\"from-idea-to-prod-model-group\",\n",
    "    pipeline_name=\"from-idea-to-prod-pipeline\",\n",
    "    base_job_prefix=\"from-idea-to-prod-pipeline\",\n",
    "    processing_instance_type=\"ml.c5.xlarge\",\n",
    "    training_instance_type=\"ml.m5.xlarge\",\n",
    "):\n",
    "    \"\"\"Gets a SageMaker ML Pipeline instance.\n",
    "\n",
    "    Args:\n",
    "        region: AWS region to create and run the pipeline.\n",
    "        role: IAM role to create and run steps and pipeline.\n",
    "        default_bucket: the bucket to use for storing the artifacts\n",
    "\n",
    "    Returns:\n",
    "        an instance of a pipeline\n",
    "    \"\"\"\n",
    "    sagemaker_session = get_session(region, default_bucket)\n",
    "    if role is None:\n",
    "        role = sagemaker.session.get_execution_role(sagemaker_session)\n",
    "\n",
    "    pipeline_session = get_pipeline_session(region, default_bucket)\n",
    "\n",
    "    # Set S3 urls for processed data\n",
    "    train_s3_url = f\"s3://{default_bucket}/{bucket_prefix}/train\"\n",
    "    validation_s3_url = f\"s3://{default_bucket}/{bucket_prefix}/validation\"\n",
    "    test_s3_url = f\"s3://{default_bucket}/{bucket_prefix}/test\"\n",
    "    \n",
    "    # Set S3 url for model artifact\n",
    "    output_s3_url = f\"s3://{default_bucket}/{bucket_prefix}/output\"\n",
    "\n",
    "    # Parameters for pipeline execution\n",
    "    # Set processing instance type\n",
    "    process_instance_type_param = ParameterString(\n",
    "        name=\"ProcessingInstanceType\",\n",
    "        default_value=processing_instance_type,\n",
    "    )\n",
    "\n",
    "    # Set training instance type\n",
    "    train_instance_type_param = ParameterString(\n",
    "        name=\"TrainingInstanceType\",\n",
    "        default_value=training_instance_type,\n",
    "    )\n",
    "\n",
    "    # Set training instance count\n",
    "    train_instance_count_param = ParameterInteger(\n",
    "        name=\"TrainingInstanceCount\",\n",
    "        default_value=1\n",
    "    )\n",
    "\n",
    "    # Set model approval param\n",
    "    model_approval_status_param = ParameterString(\n",
    "        name=\"ModelApprovalStatus\", default_value=\"PendingManualApproval\"\n",
    "    )\n",
    "\n",
    "    # Set S3 url for input dataset\n",
    "    input_s3_url_param = ParameterString(\n",
    "        name=\"InputDataUrl\",\n",
    "        default_value=input_data_url,\n",
    "    )\n",
    "\n",
    "    # processing step for feature engineering\n",
    "    sklearn_processor = SKLearnProcessor(\n",
    "            framework_version=\"0.23-1\",\n",
    "            role=role,\n",
    "            instance_type=process_instance_type_param,\n",
    "            instance_count=1,\n",
    "            sagemaker_session=pipeline_session,\n",
    "            base_job_name=f\"{base_job_prefix}/preprocess\",\n",
    "        )\n",
    "\n",
    "    # Define processing step\n",
    "    step_process = ProcessingStep(\n",
    "        name=\"PreprocessData\",\n",
    "        processor=sklearn_processor,\n",
    "        inputs=[\n",
    "            ProcessingInput(source=input_s3_url_param, destination=\"/opt/ml/processing/input\")\n",
    "        ],\n",
    "        outputs=[\n",
    "            ProcessingOutput(output_name=\"train_data\", source=\"/opt/ml/processing/output/train\", \n",
    "                             destination=train_s3_url),\n",
    "            ProcessingOutput(output_name=\"validation_data\", source=\"/opt/ml/processing/output/validation\",\n",
    "                             destination=validation_s3_url),\n",
    "            ProcessingOutput(output_name=\"test_data\", source=\"/opt/ml/processing/output/test\",\n",
    "                             destination=test_s3_url),\n",
    "        ],\n",
    "        code=os.path.join(BASE_DIR, \"preprocessing.py\"),\n",
    "    #    job_arguments=[\"--arg1\", \"arg1_value\", \"--arg2\", \"arg2_value\"],\n",
    "    )\n",
    "\n",
    "    # Training step for generating model artifacts\n",
    "    training_image = sagemaker.image_uris.retrieve(\"xgboost\", region=region, version=\"latest\")\n",
    "\n",
    "    # Instantiate an XGBoost estimator object\n",
    "    estimator = sagemaker.estimator.Estimator(\n",
    "        image_uri=training_image,\n",
    "        role=role, \n",
    "        instance_type=train_instance_type_param,\n",
    "        instance_count=train_instance_count_param,\n",
    "        output_path=output_s3_url,\n",
    "        sagemaker_session=pipeline_session,\n",
    "        base_job_name=f\"{base_job_prefix}/train\",\n",
    "    )\n",
    "\n",
    "    # Define its hyperparameters\n",
    "    estimator.set_hyperparameters(\n",
    "        num_round=150, # the number of rounds to run the training\n",
    "        max_depth=5, # maximum depth of a tree\n",
    "        eta=0.5, # step size shrinkage used in updates to prevent overfitting\n",
    "        alpha=2.5, # L1 regularization term on weights\n",
    "        objective=\"binary:logistic\",\n",
    "        eval_metric=\"auc\", # evaluation metrics for validation data\n",
    "        subsample=0.8, # subsample ratio of the training instance\n",
    "        colsample_bytree=0.8, # subsample ratio of columns when constructing each tree\n",
    "        min_child_weight=3, # minimum sum of instance weight (hessian) needed in a child\n",
    "        early_stopping_rounds=10, # the model trains until the validation score stops improving\n",
    "        verbosity=1, # verbosity of printing messages\n",
    "    )\n",
    "\n",
    "    # Define training step\n",
    "    step_train = TrainingStep(\n",
    "        name=\"Train\",\n",
    "        estimator=estimator,\n",
    "        inputs={\n",
    "            \"train\": TrainingInput(\n",
    "                s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                    \"train_data\"\n",
    "                ].S3Output.S3Uri,\n",
    "                content_type=\"text/csv\",\n",
    "            ),\n",
    "            \"validation\": TrainingInput(\n",
    "                s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                    \"validation_data\"\n",
    "                ].S3Output.S3Uri,\n",
    "                content_type=\"text/csv\",\n",
    "            ),\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # Define register step\n",
    "    step_register = RegisterModel(\n",
    "        name=\"RegisterModel\",\n",
    "        estimator=estimator,\n",
    "        model_data=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "        content_types=[\"text/csv\"],\n",
    "        response_types=[\"text/csv\"],\n",
    "        inference_instances=[\"ml.t2.medium\", \"ml.m5.large\"],\n",
    "        transform_instances=[\"ml.m5.large\"],\n",
    "        model_package_group_name=model_package_group_name,\n",
    "        approval_status=model_approval_status_param,\n",
    "    )\n",
    "\n",
    "    # Pipeline instance\n",
    "    pipeline = Pipeline(\n",
    "        name=pipeline_name,\n",
    "        parameters=[\n",
    "            process_instance_type_param,\n",
    "            train_instance_type_param,\n",
    "            train_instance_count_param,\n",
    "            model_approval_status_param,\n",
    "            input_s3_url_param,\n",
    "        ],\n",
    "        steps=[step_process, step_train, step_register],\n",
    "        sagemaker_session=pipeline_session,\n",
    "    )\n",
    "    \n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1856dd52-e4e9-455a-9d80-e4f0bdd02793",
   "metadata": {},
   "source": [
    "Copy this `pipeline.py` file from the `amazon-sagemaker-from-idea-to-production` folder to the `pipelines/fromideatoprod` folder in the project's code repository folder (replace the existing `pipeline.py` file in the folder)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f760f4bd-c5d5-4bf7-b56c-11e70fa981e1",
   "metadata": {},
   "source": [
    "### 3. Modify the build specification file\n",
    "You must modify the `codebuild-buildspec.yml` file in the project folder to reflect the new name of Python module with your pipeline and set project-specific parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07928bfd-570a-4be9-a21e-7a1160e23b71",
   "metadata": {},
   "source": [
    "First, print the value of `input_s3_url` variable with the S3 path to the source dataset. You must pass this value to the pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "736ce50f-b4a6-4b84-9c4e-f4a9f2c30711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-906545278380/from-idea-to-prod/xgboost/input/bank-additional-full.csv'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_s3_url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12f8aa7-6bb2-40bc-824f-4dd70f8d5036",
   "metadata": {},
   "source": [
    "Second, replace the value of the `input_data_url` parameter in the following cell with the value of `input_s3_url`. Execute the cell to create a build spec file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6713dcbc-4145-402a-92a2-e17b5b44c6c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting codebuild-buildspec.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile codebuild-buildspec.yml\n",
    "\n",
    "version: 0.2\n",
    "\n",
    "phases:\n",
    "  install:\n",
    "    runtime-versions:\n",
    "      python: 3.8\n",
    "    commands:\n",
    "      - pip install --upgrade --force-reinstall . \"awscli>1.20.30\"\n",
    "  \n",
    "  build:\n",
    "    commands:\n",
    "      - export PYTHONUNBUFFERED=TRUE\n",
    "      - export SAGEMAKER_PROJECT_NAME_ID=\"${SAGEMAKER_PROJECT_NAME}-${SAGEMAKER_PROJECT_ID}\"\n",
    "      - |\n",
    "        run-pipeline --module-name pipelines.fromideatoprod.pipeline \\\n",
    "          --role-arn $SAGEMAKER_PIPELINE_ROLE_ARN \\\n",
    "          --tags \"[{\\\"Key\\\":\\\"sagemaker:project-name\\\", \\\"Value\\\":\\\"${SAGEMAKER_PROJECT_NAME}\\\"}, {\\\"Key\\\":\\\"sagemaker:project-id\\\", \\\"Value\\\":\\\"${SAGEMAKER_PROJECT_ID}\\\"}]\" \\\n",
    "          --kwargs \"{\\\"region\\\":\\\"${AWS_REGION}\\\",\\\"sagemaker_project_arn\\\":\\\"${SAGEMAKER_PROJECT_ARN}\\\",\\\"role\\\":\\\"${SAGEMAKER_PIPELINE_ROLE_ARN}\\\",\\\"default_bucket\\\":\\\"${ARTIFACT_BUCKET}\\\",\\\"input_data_url\\\":\\\"s3://sagemaker-us-east-1-906545278380/from-idea-to-prod/xgboost/input/bank-additional-full.csv\\\"}\"\n",
    "      - echo \"Create/Update of the SageMaker Pipeline and execution completed.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd4a948-8a46-4d75-b15a-c15d3d4873c4",
   "metadata": {},
   "source": [
    "Copy the `codebuild-buildspec.yml` file from the `amazon-sagemaker-from-idea-to-production` folder to the project's code repository folder. Replace the the existing build spec file.\n",
    "\n",
    "We did three changes in the build spec file:\n",
    "1. Modified the `run-pipeline` `--module-name` parameter value from `pipelines.abalone.pipeline` to the new path `pipelines.fromideatoprod.pipeline`\n",
    "2. Removed some parameters from the `kwargs` list to make use of `get_pipeline()` function default parameter values\n",
    "3. Added an Amazon S3 url to the source data to the `kwargs` parameter list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcfd6d3-2116-42e9-988b-e377fcd4b912",
   "metadata": {},
   "source": [
    "Finally, open the `setup.py` file in the project's code repository folder and replace the line `required_packages = [\"sagemaker==2.XX.0\"]` with `required_packages = [\"sagemaker\"]`. Save your changes.\n",
    "\n",
    "Now you are ready to launch the CI/CD model building pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ee8789-1d8f-4a06-a958-8c244fa9a869",
   "metadata": {},
   "source": [
    "## Run CI/CD model building pipeline\n",
    "‚ùó Make sure you are in the local folder that contains the **repository code** in Studio file browser. The folder name looks like `sagemaker-<project-name>-<project-id>-modelbuild`.\n",
    "\n",
    "Choose the Git icon in the Studio sidebar. Stage, commit, and push all the changes in the project repository. \n",
    "\n",
    "Alternatively, you can run all git commands from the Studio system terminal:\n",
    "```sh\n",
    "cd ~/<PROJECT-FOLDER>/<PROJECT-CODE-REPOSITORY-FOLDER>\n",
    "git add -A\n",
    "git commit -am \"customize project\"\n",
    "git push\n",
    "```\n",
    "\n",
    "After pushing your code changes, the MLOps project initiates a run of the CodePipeline pipeline that updates and executes the SageMaker model building pipeline. This new pipeline execution creates a new model version in the model package group in the SageMaker model registry.\n",
    "\n",
    "You can follow up the execution of the pipeline in **SageMaker resources** > **Pipelines**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30f9944-4659-4e53-9d99-10a58eac4cdf",
   "metadata": {},
   "source": [
    "## View the details of a new model version\n",
    "1. In the Studio sidebar, choose the **SageMaker resources** icon\n",
    "2. Select **Model registry** from the dropdown list\n",
    "3. Select the name of the model package group you created in the step 3 notebook (`from-idea-to-prod-model-group`) and double-click on it to open the model group\n",
    "4. In the list of model versions, double-click on the latest version of the model\n",
    "\n",
    "![](img/model-package-group.png)\n",
    "\n",
    "On the model version tab that opens, you can browse activity, [model version details](https://docs.aws.amazon.com/sagemaker/latest/dg/model-registry-details.html), and [data lineage](https://docs.aws.amazon.com/sagemaker/latest/dg/lineage-tracking.html). \n",
    "\n",
    "![](img/model-version-details.png)\n",
    "\n",
    "In a real-world project you add various model attributes and additional model version metadata such as [model quality metrics](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-model-quality-metrics.html), [explainability](https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-model-explainability.html) and [bias](https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-measure-post-training-bias.html) reports, load test data, and [inference recommender](https://docs.aws.amazon.com/sagemaker/latest/dg/inference-recommender.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fcc951-0ea2-43f3-89f0-5b2982334d11",
   "metadata": {},
   "source": [
    "## Continue with the step 5\n",
    "open the step 5 [notebook](05-deploy.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afba0bb-5a1d-4399-b3bc-3664be5e40b9",
   "metadata": {},
   "source": [
    "## Further development ideas\n",
    "- You can use a SageMaker-provided [MLOps template for model building, training, and deployment with third-party Git repositories using Jenkins](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-projects-templates-sm.html#sagemaker-projects-templates-git-jenkins)\n",
    "- Create a [custom SageMaker project template](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-projects-templates-custom.html) to cover your specific project requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e55501-6c9c-40a7-89f3-04530e147a26",
   "metadata": {},
   "source": [
    "## Additional resources\n",
    "- [Amazon SageMaker Pipelines lab in SageMaker Immersion Day](https://catalog.us-east-1.prod.workshops.aws/workshops/63069e26-921c-4ce1-9cc7-dd882ff62575/en-US/lab6)\n",
    "- [Enhance your machine learning development by using a modular architecture with Amazon SageMaker projects](https://aws.amazon.com/blogs/machine-learning/enhance-your-machine-learning-development-by-using-a-modular-architecture-with-amazon-sagemaker-projects/)\n",
    "- [Dive deep into automating MLOps](https://www.youtube.com/watch?v=3_cHnk9VSfQ)\n",
    "- [SageMaker MLOps Project Walkthrough](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-projects-walkthrough.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f175fc-3eea-4777-9047-329c5098eed7",
   "metadata": {},
   "source": [
    "# Shutdown kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "feb3ee45-d774-4d7d-8954-6f5479e20090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<p><b>Shutting down your kernel for this notebook to release resources.</b></p>\n",
       "<button class=\"sm-command-button\" data-commandlinker-command=\"kernelmenu:shutdown\" style=\"display:none;\">Shutdown Kernel</button>\n",
       "        \n",
       "<script>\n",
       "try {\n",
       "    els = document.getElementsByClassName(\"sm-command-button\");\n",
       "    els[0].click();\n",
       "}\n",
       "catch(err) {\n",
       "    // NoOp\n",
       "}    \n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "\n",
    "<p><b>Shutting down your kernel for this notebook to release resources.</b></p>\n",
    "<button class=\"sm-command-button\" data-commandlinker-command=\"kernelmenu:shutdown\" style=\"display:none;\">Shutdown Kernel</button>\n",
    "        \n",
    "<script>\n",
    "try {\n",
    "    els = document.getElementsByClassName(\"sm-command-button\");\n",
    "    els[0].click();\n",
    "}\n",
    "catch(err) {\n",
    "    // NoOp\n",
    "}    \n",
    "</script>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10fb645-0789-4fc4-a662-1502d7b30fd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
